{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#recode-sph-solver-2d-ns","title":"RECODE-SPH-SOLVER-2D-NS","text":"SPH simulation"},{"location":"#description","title":"Description","text":"<p>In this project we present a numerical code in C++ which solves the two-dimensional Navier-Stokes equations using the smoothed-particle hydrodynamics (SPH) approach. The focus lies in the implementation (and documentation) of good C++ practices and the development of skills related to efficient, robust, extensible and readable scientific code. The learning process regarding this project can be twofold:</p> <p>1) The student can study the material provided in the <code>main</code> branch of the present repository. It is independent of all the other branches and can be used as a standalone educational resource. In this the implemented SPH methodology is explained as well as the structure of the source code and the post-processing scripts.</p> <p>2) The student can start by studying progressively the branches <code>v0</code> - <code>v5</code> in order to experience the process which was followed in order to improve and optimize the herein code. Several comments have been added for each individual version in the corresponding branch to highlight the improvements which were implemented compared to its ancestors.</p>"},{"location":"#learning-outcomes","title":"Learning Outcomes","text":"<ul> <li>I/O (input/output)</li> <li>OOP (object-oriented programming)</li> <li>C++ containers</li> <li>Performance and memory optimization tools and skills</li> </ul> Task Time Reading 15 hours Practicing 10 hours"},{"location":"#requirements","title":"Requirements","text":""},{"location":"#academic","title":"Academic","text":"<ul> <li> <p>Experience with basic programming concepts (for loops, functions, reading and writing files etc.).</p> </li> <li> <p>Some experience with C++ (familiarity with pointers, C++ classes and the use of external libraries).</p> </li> <li> <p>Basic understanding of numerical analysis concepts (time marching, temporal integration etc.)</p> </li> </ul>"},{"location":"#system","title":"System","text":"<p>For manual installation of the program and its dependencies, you will need the following:</p> <ul> <li>Python 3.11 installed</li> <li>A C++ toolchain along with the necessary development libraries: <ul> <li>build-essential </li> <li>libboost-program-options-dev, </li> <li>clang-format</li> <li>cmake. </li> </ul> </li> </ul> <p>You will also need to install the required Python packages by running the command </p> <ul> <li>\"pip install -r requirements.txt.\"</li> </ul> <p>If you haven't already, set up the pre-commit hook by executing the </p> <ul> <li>\"pre-commit install\" command.</li> </ul> <p>Following these steps manually will establish the environment necessary for the program to run successfully. Alternatively, to streamline the process, consider using the provided Dockerfile to create a Docker image and deploy the program in a containerized environment, or you can simply use the github codespaces functionality by following the instructions provided in the section GitHub Codespaces.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To better comprehend this exemplar, it's recommended to follow the outlined procedure by sequentially reviewing the chapters. The suggested workflow ensures a step-by-step understanding, beginning with the foundational SPH algorithm elucidated in the code (Smoothed-Particle Hydrodynamics (SPH)-Adaptive timestep), followed by an exploration of its implementation aspects (Code overview - Efficient programming). Once you've grasped the code intricacies, it's time to put it into action. In the sections Code execution - Profiling you will learn how to run the code, assess its performance and post process the data it generates. Depending on your learning preference, you may opt for a reversed approach, initiating with code execution and subsequently delving under the hood to explore the C++ code. It works both ways!</p> <p>For additional study and practice, delve into Clang format, Building with Cmake and Exercises. These sections offer deeper insights into the project's good practices and provide opportunities to enhance your coding skills.</p>"},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>.\n\u251c\u2500\u2500 docs\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u251c\u2500\u2500 1.SPH.md\n\u2502   \u251c\u2500\u2500 2.Code_Overview.md\n\u2502   \u251c\u2500\u2500 3.IO_Overview.md\n\u2502   \u251c\u2500\u2500 4.OOP_Concepts.md\n\u2502   \u251c\u2500\u2500 5.STL.md\n\u2502   \u251c\u2500\u2500 6.Efficient_Programming.md\n\u2502   \u251c\u2500\u2500 7.Neighbour_Search.md\n\u2502   \u251c\u2500\u2500 8.Adaptive_Timestep.md\n\u2502   \u251c\u2500\u2500 9.Code_Execution.md\n\u2502   \u251c\u2500\u2500 10.GH_Codespaces.md\n\u2502   \u251c\u2500\u2500 11.Profiling.md\n\u2502   \u251c\u2500\u2500 12.Post_Analysis.md\n\u2502   \u251c\u2500\u2500 A1.ClangFormat.md\n\u2502   \u251c\u2500\u2500 A2.CMake.md\n\u2502   \u2514\u2500\u2500 B1.Exercises.md\n\u251c\u2500\u2500 exec\n\u2502   \u251c\u2500\u2500 build\n\u2502   \u2514\u2500\u2500 input\n\u2502       \u251c\u2500\u2500 case.txt\n\u2502       \u251c\u2500\u2500 constants.txt\n\u2502       \u251c\u2500\u2500 domain.txt\n\u2502       \u251c\u2500\u2500 ic-block-drop.txt\n\u2502       \u251c\u2500\u2500 ic-droplet.txt\n\u2502       \u251c\u2500\u2500 ic-one-particles.txt\n\u2502       \u251c\u2500\u2500 ic-two-particles.txt\n\u2502       \u251c\u2500\u2500 ic-three-particles.txt\n\u2502       \u2514\u2500\u2500 ic-four-particles.txt\n\u251c\u2500\u2500 notebooks\n\u251c\u2500\u2500 post\n\u2502   \u251c\u2500\u2500 plot_energies.ipynb\n\u2502   \u251c\u2500\u2500 plot_energies.py\n\u2502   \u251c\u2500\u2500 simulation_animation.ipynb\n\u2502   \u251c\u2500\u2500 simulation_animation.py\n\u2502   \u251c\u2500\u2500 visualise_particles.ipynb\n\u2502   \u2514\u2500\u2500 visualise_particles.py\n\u2514\u2500\u2500 src\n    \u251c\u2500\u2500 CMakeLists.txt\n    \u251c\u2500\u2500 fluid.cpp\n    \u251c\u2500\u2500 fluid.h\n    \u251c\u2500\u2500 initial_conditions.cpp\n    \u251c\u2500\u2500 initial_conditions.h\n    \u251c\u2500\u2500 main_prog_funcs.h\n    \u251c\u2500\u2500 particles.cpp\n    \u251c\u2500\u2500 particles.h\n    \u251c\u2500\u2500 SPH-main.cpp\n    \u251c\u2500\u2500 sph_solver.cpp\n    \u2514\u2500\u2500 sph_solver.h\n</code></pre> <sub>Chris Cooling</sub> <sub>Christos Petalotis</sub> <sub>Katerina Michalickova</sub> <sub>Dan Cummins</sub> <sub>Vyron Avramidis</sub> <sub>Vasileios Christou</sub> <sub>George Efstathiou</sub> <sub>George Efstathiou</sub>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the BSD-3-Clause license</p>"},{"location":"1.SPH/","title":"Smoothed-Particle Hydrodynamics (SPH)","text":"<p>Smoothed-particle hydrodynamics (SPH) is a branch of computational fluid dynamics, which belongs in the category of particle-based and mesh-free methods. It was first developed for astrophysical flows related problems and has gained an increasing popularity over the last few years due to its very good applicability and easy extensibility in problems describing free surface and multiphase flows in both simple and complex geometries.</p> <p>In the SPH formulation, the fluid is approximated as being comprised of identical fictitious particles whose interpolated properties can approximate any function  that is of interest over a domain :</p> <p> </p> <p>In this equation,  is a kernel function and  is defined as the smoothing length that characterizes the size of the support domain of the kernel. The discrete equivalent of the above expression for the th particle can be written as</p> <p> </p> <p>The kernel function provides the weight which is assigned to each particle based on their distance from the point of interest (i.e. the point where the function  is to be evaluated). The movement of the particles obeys Newton's second law of motion and the forces applied on the particles are being calculated as explained above.</p> <p>More information on SPH and its applications can be found in the following resources</p> <ul> <li>http://dx.doi.org/10.1098/rspa.2019.0801</li> <li>https://doi.org/10.3389/fams.2021.797455</li> <li>https://www.ansys.com/en-gb/blog/what-is-sph-simulation</li> <li>https://www.dive-solutions.de/blog/sph-basics</li> <li>https://doi.org/10.5194/gmd-11-2691-2018</li> <li>https://arxiv.org/pdf/2104.00537.pdf</li> </ul>"},{"location":"1.SPH/#the-algorithm","title":"The algorithm","text":"<p>In this exemplar the following algorithm which describes the solution steps of a 2D formulation of the Navier-Stokes equation is implemented:</p>"},{"location":"1.SPH/#density","title":"Density","text":"<p>The density of the fluid associated with each particle  is approximated as</p> <p> </p> <p>where  and  is the mass of a particle and the kernel density function for density,  is given by</p> <p> </p> <p>where  is the distance between particle  and particle , normalised by the interaction radius , given by</p> <p> </p> <p>The interaction radius describes the distance over which a particle has an influence on the behaviour of the system.</p>"},{"location":"1.SPH/#pressure","title":"Pressure","text":"<p>The pressure is calculated based on the ideal gas law</p> <p> </p> <p>where  is a resting density and  is a gas constant.</p>"},{"location":"1.SPH/#pressure-force","title":"Pressure force","text":"<p>The force exerted on the particle due to pressure from neighboring fluid particles is calculated as</p> <p> </p> <p>where  is the the kernel density function for pressure :</p> <p> </p>"},{"location":"1.SPH/#viscous-force","title":"Viscous force","text":"<p>The force acting on each particle due to viscous effects is calculated as</p> <p> </p> <p>where ,  is the velocity of particle ,  is the dynamic viscosity, and  is given by:</p> <p> </p>"},{"location":"1.SPH/#gravity-force","title":"Gravity force:","text":"<p>Finally, the force due to gravity is given by:</p> <p> </p> <p>where  is the acceleration due to gravity.</p>"},{"location":"1.SPH/#acceleration","title":"Acceleration","text":"<p>The acceleration of particle  is given by:</p> <p> </p>"},{"location":"1.SPH/#time-integration","title":"Time integration","text":"<p>We solve the equation as a function of time by finding the velocity and position of each particle at each of a number of time steps. We denote a property  of particle  at time step  as . The state of the property half way between time steps  and  is denoted as .</p> <p>We begin with the initial conditions of the system, which are the positions and velocities of the particles at time . We iteratively use the state of the system at time step  to find the state of the system at time step  using a leap-frog scheme, which provides improved stability characteristics:</p> <p> </p> <p>However, because the velocity is calculated at half-steps, we need to initialise the scheme on the first time step using:</p> <p> </p> <p>where  is the time step size. To ensure convergence, a small time-step is required. A value of   is suggested.</p>"},{"location":"1.SPH/#initial-condition","title":"Initial Condition","text":"<p>To initialise the simulation, one or more particles must be specified. These should be evenly distributed.</p> <p>Once the particles are placed, the particle densities should be evaluated with an assumed mass of  and the mass subsequently scaled so that the density is equal to the reference density:</p> <p> </p>"},{"location":"1.SPH/#boundary-conditions","title":"Boundary Conditions","text":"<p>All the boundaries are solid walls with damped reflecting boundary conditions. If particles are within a distance h of the boundary, their velocity and position should be updated to reverse the motion of the particle and keep it within the domain. For example, on the right boundary, the -component of position and velocity would be modified as:</p> <p> </p>"},{"location":"2.Neighbour_Search/","title":"Neighbour Searching Algorithm","text":"<p>In SPH, each particle is only influenced by the particles that are within a maximum distance (the radius of influence ) of it. These particles are usually called the particle's neighbours, and there are numerous approaches and algorithms that can be used to identify them. There are approaches that are as simple as just checking the distance between every pair of particles in each iteration. However, as the number of particles increases, the inefficiency of such algorithms constitutes them unacceptable, and a more sophisticated solution is needed.</p>"},{"location":"2.Neighbour_Search/#big-o-notation","title":"Big O Notation","text":"<p>Big O notation is a mathematical notation used to describe the asymptotic behaviour of a function or algorithm. It is commonly used in computer science to analyze the performance of algorithms in terms of their time complexity. Big O notation provides a way to classify algorithms based on their efficiency and scalability. It helps us understand how the time or space requirements of an algorithm grow as the size of the input increases. In Big O notation, we express the upper bound or worst-case scenario of an algorithm's time complexity in terms of a mathematical function. For example, an algorithm with a time complexity of  means that its execution time grows linearly with the size of the input. An algorithm with  time complexity means that its execution time grows quadratically with the size of the input, and so on.</p>"},{"location":"2.Neighbour_Search/#brute-force-approach","title":"Brute Force Approach","text":"<p>A brute force algorithm is a straightforward approach to solving a problem that exhaustively tries all possible solutions. For certain problems, this can lead to exponential time complexity, making brute force algorithms impractical for large inputs.</p> <p>In our initial implementation, we followed a brute force approach, where, for each particle, we would iterate over all particles, calculate their separation, compare it to the radius of influence, and finally, if the particle was a neighbour, we would proceed to the SPH calculations. This approach resulted in a complexity of , indicating an inefficient algorithm that should be replaced.</p>"},{"location":"2.Neighbour_Search/#cells-neighbour-searching","title":"Cells Neighbour Searching","text":"<p>A cells neighbour searching algorithm is an optimisation technique used to efficiently find neighbouring elements within a spatial grid or partitioned space. Instead of comparing each element with every other element, this approach divides the space into smaller cells or buckets and only considers elements within the same or neighbouring cells. For example, in the context of particle simulation or computational fluid dynamics, a cells neighbour searching algorithm can significantly reduce the number of pairwise comparisons needed to calculate interactions between particles. By organizing particles into spatial cells and only considering interactions between particles within the same or adjacent cells, the algorithm achieves a time complexity close to , making it much more scalable and efficient than brute force approaches for large datasets. In more detail:</p> <ul> <li> <p>Creating the grid and placing particles in cells: This step involves iterating over all particles and determining their cell index based on their position. This step has a time complexity of .</p> </li> <li> <p>Searching for neighbours: Once the particles are placed in cells, searching for neighbours involves iterating over each particle and checking neighbouring cells to find particles within the radius of influence. The complexity of this step depends on the number of neighbouring cells each particle needs to check. If each particle checks a constant number of neighbouring cells, the complexity remains .</p> </li> <li> <p>Iterating over particle neighbours: Finally, iterating over each particle's neighbours to perform SPH calculations typically has a complexity of , where  is the average number of neighbours per particle and .</p> </li> </ul> Schematic representation of the domain which is split in cells (black lines) and the area of influence (red circles) around the particles (black dots). The snapshot was taken from https://doi.org/10.2312/cgvc.20191258. <p>The overall time complexity of the cells neighbour searching algorithm depends on the number of neighbours each particle checks. If the grid structure is properly optimised, the algorithm can achieve close to  complexity.</p> <p>In the current implementation, we follow a neighbour searching algorithm that is based on partitioning the domain into square grid cells. These side length of these cells is equal to the radius of influence. The benefit of this design decision is that we know in advance that a particle's neighbours may only lie in the same cell as the particle, or in one of the neighbouring cells. We therefore do not need to iterate over all particles and check their separations before every calculation.</p> <pre><code>/* **************************** sph_solver.cpp **************************** */\n\nvoid SphSolver::createGrid(Fluid &amp;data) {\n  numberOfParticles = data.getNumberOfParticles();\n  neighbourParticles.resize(numberOfParticles);\n\n  double radiusOfInfluence = data.getRadInfl();\n  int cellsRows =\n      static_cast&lt;int&gt;(std::ceil((topWall - bottomWall) / radiusOfInfluence));\n  int cellsCols =\n      static_cast&lt;int&gt;(std::ceil((rightWall - leftWall) / radiusOfInfluence));\n  numberOfCells = cellsRows * cellsCols;\n  cells.reserve(numberOfCells);\n  neighbourCells.reserve(numberOfCells);\n\n  assignNeighbourCells(cellsRows, cellsCols);\n}\n</code></pre> <p>The first step of the algorithm is to turn the domain to a grid, by splitting it into cells. This logic is implemented in the <code>SphSolver::createGrid()</code> function. It should be noted that all neighbour searching functions have been implemented as member functions of the <code>SphSolver</code> class, since the algorithm is a part of the SPH system. In this function, we calculate the number of cell rows and columns that form the grid, by dividing the corresponding domain dimension (length and width accordingly) by the cell side length (radius of influence). Since the result of this division is not guaranteed to be an integer, we use <code>ceil</code> to get the next integer number, and <code>static_cast&lt;int&gt;</code> to change the <code>double</code> to an <code>int</code>, which is the final number of cell rows/columns. The reason we use <code>ceil</code> to round up to the next integer, instead of just rounding down by simply casting the <code>double</code> to an <code>int</code>, is to be sure that the whole domain is considered. This way, even though parts of some cells may lie outside the domain, it is guaranteed that the algorithm will not miss any particles. </p> <p>Finally, we resize the two containers that will be used to store each cell's particles (<code>cells</code>) and neighbouring cells (<code>neighbourCells</code>). Each of these containers is a vector of vectors. The outer vector is used to store cells. In the case of the <code>cells</code> container, each inner vector will hold the indices of the particles that lie within the cell, and in the case of the <code>neighbourCells</code>, the inner vector will hold the indices of the current cell's neighbouring cells. This way, the algorithm will be able to search for neighbour particles both in a cell, as well as in its neighbouring cells.</p> <p><pre><code>/* **************************** sph_solver.cpp **************************** */\n\nvoid SphSolver::assignNeighbourCells(int cellsRows, int cellsCols) {\n  // Each cell could have at most 8 neighbours (and most of them do), so reserve\n  // the memory\n  for (int i = 0; i &lt; numberOfCells; i++) {\n    neighbourCells[i].reserve(maxNeighbourCells);\n  }\n  // Flags to check if the cell is on the edge or not\n  bool top = false;\n  bool left = false;\n  bool right = false;\n  bool bottom = false;\n\n  for (size_t i = 0; i &lt; numberOfCells; i++) {\n    // Cell has a bottom neighbour\n    if (i &gt;= cellsCols) {\n      neighbourCells[i].push_back(i - cellsCols);\n      bottom = true;\n    }\n    ...\n    // If the cell is not on the edge, add the diagonal neighbours\n    if (bottom &amp;&amp; top &amp;&amp; left &amp;&amp; right) {\n      neighbourCells[i].push_back(i - 1 - cellsCols);\n      neighbourCells[i].push_back(i - 1 + cellsCols);\n      neighbourCells[i].push_back(i + 1 - cellsCols);\n      neighbourCells[i].push_back(i + 1 + cellsCols);\n      // If the cell is on the edge, add only specific neighbours\n    } else {\n      // Add bottom-left diagonal neighbour\n      if (bottom &amp;&amp; left) {\n        neighbourCells[i].push_back(i - 1 - cellsCols);\n      }\n      // Add bottom-right diagonal neighbour\n      if (bottom &amp;&amp; right) {\n      ...\n    }\n    // Reset the flags\n    top = false;\n    left = false;\n    right = false;\n    bottom = false;\n  }\n}\n</code></pre> The next step of the algorithm is to record which cells neighbour each cell. This logic is implemented in the <code>SphSolver::assignNeighbourCells()</code> function. Depending on its position in the grid (middle, edge, corner) a cell could have 8, 5, or 3 neighbouring cells accordingly. Note that, since we know this information, we start with reserving the required memory for each cell vector, so that the following <code>push_backs</code> do not need to spend time re-allocating memory for the vector and copying the elements to the new memory. In this function, while we iterate over all cells, we use several flags (<code>top</code>, <code>left</code>, <code>right</code>, <code>bottom</code>), combined with several rules, to find each cell's neighbouring cells. For instance, all cell indices greater than or equal to than the number of cell columns, denote that the cell iterator has passed the first (lowest) row of the grid, a fact that means that the current cell has a \"bottom neighbour\", and therefore, in the <code>neighbourCells</code> container, we add the index of the \"bottom cell\" (<code>push_back(i - cellsCols)</code>) to the current cell's inner vector (<code>neighbourCells[i]</code>), and set <code>bottom</code> to <code>true</code>. Following similar rules, we identify each cell's position and assign the right neigbhouring cells to it, including the diagonal neighbours. Finally, we reset the flags and move to the next cell.</p> <p>Up to this point, the algorithm's steps included logic that does not change during the time integration procedure, and therefore, the aforementioned functions are only used during initialisation (called at the end of <code>initialise()</code> in <code>SPH-main.cpp</code>). However, the next steps are steps that need to be followed in each iteration, as the particles' positions change.</p> <pre><code>/* **************************** sph_solver.cpp **************************** */\n\nvoid SphSolver::placeParticlesInCells(Fluid &amp;data) {\n  for (size_t i = 0; i &lt; numberOfCells; i++) {\n    int currentCellSize = cells[i].size();\n    cells[i].clear();\n    cells[i].reserve(\n        static_cast&lt;int&gt;(memoryReservationFactor * currentCellSize));\n  }\n\n  double radiusOfInfluence = data.getRadInfl();\n  int cellsCols =\n      static_cast&lt;int&gt;(std::ceil((rightWall - leftWall) / radiusOfInfluence));\n  for (size_t i = 0; i &lt; numberOfParticles; i++) {\n    double positionX = data.getPositionX(i);\n    double positionY = data.getPositionY(i);\n    int j = static_cast&lt;int&gt;(positionX / radiusOfInfluence) +\n            static_cast&lt;int&gt;(positionY / radiusOfInfluence) * cellsCols;\n    cells[j].push_back(i);\n  }\n}\n</code></pre> <p>The first thing that the algorithm should do in each iteration is to place each particles into their corresponding cells, according to their position in the domain. This functionality is included in the <code>SphSolver::placeParticlesInCells()</code> function. First, the <code>cells</code> vector needs to be cleared to remove any particles that may have been placed in it during the previous iteration. However, before clearing the vector, its current size can be used to optimise the function's performance. Similarly to the previous function, we want to reserve the memory that the vector will need in this iteration in order to save time during <code>push_backs</code>. The difference is that in this case, we cannot be sure about the number of elements that each cell will hold. However, we know that each particle's position does not change significantly in each iteration, and that the number of particles in each cell will be approximately the same as in the previous iteration. Therefore, after clearing a cell's vector, we reserve memory for this iteration equal to the vector's previous size, multiplied by a factor (1.1) to accommodate for new particles that may enter the cell. This reserves an amount of memory for each cell that is expected to be enough, and so minimises the time spent on memory reallocation and copying as more particles are added to each cell. </p> <p>After memory reservation, the function iterates over all particles, gets their coordinates, and based on those, decides on the index of the cell in which the particle should be placed. Finally, the index of the particle is added to the appropriate inner vector of the <code>cells</code> container (<code>cells[j].push_back[i]</code>).</p> <pre><code>/* **************************** sph_solver.cpp **************************** */\n\nvoid SphSolver::neighbourParticlesSearch(Fluid &amp;data) {\n  int currentNumberOfNeighbours;\n  for (size_t i = 0; i &lt; numberOfParticles; i++) {\n    currentNumberOfNeighbours = neighbourParticles[i].size();\n    neighbourParticles[i].clear();\n    neighbourParticles[i].reserve(\n        static_cast&lt;int&gt;(memoryReservationFactor * currentNumberOfNeighbours));\n  }\n\n  placeParticlesInCells(data);\n\n  double distance, distanceX, distanceY;\n  // For each cell, for each particle in the cell, find neighbour particles in\n  // the cell\n  for (size_t i = 0; i &lt; numberOfCells; i++) {\n    for (size_t j = 0; j &lt; cells[i].size(); j++) {\n      for (size_t k = 0; k &lt; cells[i].size(); k++) {\n        if (cells[i][j] != cells[i][k]) {\n          distanceX =\n              data.getPositionX(cells[i][j]) - data.getPositionX(cells[i][k]);\n          distanceY =\n              data.getPositionY(cells[i][j]) - data.getPositionY(cells[i][k]);\n          distance = sqrt(distanceX * distanceX + distanceY * distanceY);\n\n          if (distance &lt;= data.getRadInfl()) {\n            neighbourParticles[cells[i][j]].push_back({cells[i][k], distance});\n          }\n        }\n      }\n    }\n  }\n  ...\n}\n</code></pre> <p>After all particles have been placed in cells, the actual neighbour searching occurs. We know that a particle's neighbours could only lie in the same cell or in a neighbouring cell. In the <code>SphSolver::neighbourParticlesSearch</code> function, for each cell, for each particle in the cell, we iterate over all other particles in the same cell, calculate the pair's separation, and if it is lower than or equal to the radius of influence, we count the second particle as a neighbour of the first particle. In order to store each particle's neighbours, as well as their distance to the particle, we utilise a container of type <code>vector&lt;vector&lt;pair&lt;int, double&gt;&gt;&gt;</code>. In this container, the outer vector accounts for each particle and its size should be equal to the <code>numberOfParticles</code>. The inner vector is used to push back \"neighbour-distance pairs\". Note that the memory reservation approach used for the cell vectors is also followed in this case, since the number of a particle's neighbours is not expected to change dramatically compared to the previous iteration. Then, for each particle's neighbour, we store a pair of the neighbour's index (<code>int</code>) and the distance between the particle and its neighbour (<code>double</code>). This container provides a way to store and access each particle's neighbours and their corresponding distances during our calculations. Finally, the whole process is repeated for each neighbouring cell of the current cell, so that we are sure that we have identified all neighbours for each particle.</p> <pre><code>/* **************************** sph_solver.cpp **************************** */\n\ndouble SphSolver::calcViscousForce(Fluid &amp;data,\n                                   std::function&lt;double(int)&gt; getVelocity,\n                                   int particleIndex) {\n  double sum = 0.0;  // Initializing the summation\n  double normalisedDistance;\n  double velocity = getVelocity(particleIndex);\n  double mass = data.getMass();\n  double radiusOfInfluence = data.getRadInfl();\n  size_t neighbourIndex;\n\n  for (size_t j = 0; j &lt; neighbourParticles[particleIndex].size(); j++) {\n    neighbourIndex = neighbourParticles[particleIndex][j].first;\n\n    if (particleIndex != neighbourIndex) {\n      normalisedDistance =\n          neighbourParticles[particleIndex][j].second / radiusOfInfluence;\n      sum += (mass / data.getDensity(neighbourIndex)) *\n             (velocity - getVelocity(neighbourIndex)) *\n             (fourtyPih4 * (1.0 - normalisedDistance));\n    }\n  }\n\n  return -data.getViscosity() * sum;\n}\n</code></pre> <p>The neighbour searching algorithm introduces some complexity and overhead to the code compared to a brute force comparison of every particle-pair. However, for domains much larger than the radius of influence containing larger number of particles, the neighbour searching algorithm provides a significantly more efficient way to identify the particles that affect each particle during the SPH calculations. Even though the code may seem more complex, with up to four nested <code>for</code> loops, most of these loops iterate over a low number of neighbour particles. Additionally, the initial <code>numberOfParticles</code> range loop that was used during each iteration's calculations, as well as the distance checks, have now been replaced by a simple and faster iteration over each particle's neighbours (<code>for (int j = 0; j &lt; neighbourParticles[particleIndex].size(); j++)</code>), resulting in significantly lower execution times compared to the brute force approach, especially as the number of particles grows.</p>"},{"location":"3.Adaptive_Timestep/","title":"Adaptive timestep","text":""},{"location":"3.Adaptive_Timestep/#motivation","title":"Motivation","text":"<p>When engaging in numerical integration, the selection of the timestep relies on both the parameters of the problem and the chosen numerical scheme for discretised equations. An incorrect choice may lead to numerical instabilities, potentially resulting in a non-physical solution and program crashes. In computational fluid dynamics (CFD), a preventive measure against such issues is the use of the Courant-Friedrichs-Lewy (CFL) criterion. This criterion ensures that the numerical speed of propagation remains smaller than the one characterizing the physical problem, preventing information loss in each timestep.</p> <p>One approach to maintaining numerical stability is to preset a timestep that is known a priori (although not always feasible) to be sufficiently small, consistently meeting the CFL criterion and encompassing all timescales during the simulation. However, this method presents two challenges. Firstly, a timestep analysis must be conducted for each new simulated case. Secondly, there is a risk of over-resolving the temporal aspect of the problem, leading to unnecessary computations and increased CPU time for the program. To address this, many CFD codes employ an adaptive timestep procedure, dynamically adjusting the timestep during runtime based on the smallest timescales that require resolution for stability.</p>"},{"location":"3.Adaptive_Timestep/#implementation","title":"Implementation","text":"<p>In this project, the use of adaptive timestepping is optional and determined in the <code>case.txt</code> file as a boolean variable. If it is used, a small timestep () overwrites that specified in the <code>case.txt</code> file. The criterion used in this project is:</p> <p> </p> <p>where  and  are the maximum absolute velocity and absolute acceleration over all particles respectively, which are evaluated in the functions <code>SphSolver::updatePosition()</code>, <code>SphSolver::boundaries()</code> and <code>SphSolver::velocityIntegration</code>. The factors  and  are adjustable coefficients and may vary for different applications and fluids. Herein, in the default cases we make a choice of a strict criterion ( and , smallest reported values here) to ensure that the code can operate in a variety of applications. These parameters can also be changed in the <code>case.txt</code> file. The timestep is updated at the end of every time iteration by calling the following function:</p> <pre><code>void SphSolver::adaptiveTimestep(Fluid &amp;data) {\n  double h = data.getRadInfl();\n\n  if (maxVelocity == 0.0 || maxAcceleration == 0.0) {\n    // Set the timestep to the default value to avoid division by zero\n    dt = (maxVelocity == 0.0 &amp;&amp; maxAcceleration == 0.0) ? 1e-4\n         : (maxVelocity == 0.0) ? coeffCfl2 * pow(h / maxAcceleration, 0.5)\n                                : coeffCfl1 * h / maxVelocity;\n\n    // Terminate the integration process because the particles will not move any\n    // further\n    termination_flag = (maxVelocity == 0.0 &amp;&amp; maxAcceleration == 0.0);\n  } else {\n    // Update the timestep based on the CFL number\n    dt = std::min(coeffCfl1 * h / maxVelocity,\n                  coeffCfl2 * pow(h / maxAcceleration, 0.5));\n  }\n\n}\n</code></pre> <p>From the code snippet above, it can be seen that in the case where there is no velocity or acceleration of particles, the simulation will stop because the system will have definitely reached an equilibrium state and therefore no further calculations are needed. There is also the case where one of these quantities is zero and this means that a singularity can appear. To avoid such an incidence, when one of the velocity or acceleration is zero, only the criterion which makes use of the non-zero value is used. </p>"},{"location":"3.Adaptive_Timestep/#efficiency-and-further-considerations","title":"Efficiency and further considerations","text":"<p>With the default factors  and , the adaptive timestep approach required 15994 iterations to simulate a falling droplet of 800 particles and radius equal to 0.1, in opposition to the constant timestep approach which required 20000 iterations. A selection of  and  produced the result in only 8188 iterations.</p> Effect of adaptive timestep. <p>Regarding the constant timestep, small overshoots of the energy plots are present. These are smoothed out in the adaptive timestep cases, despite the fact that the program required a smaller amount of iterations to be executed. Regarding the adaptive timestep cases, the results are similar for both simulations which means that for this case a more relaxed than the default criterion is applicable. Although the adaptive timestep introduces an extra layer of robustness (stability of cases with high number of particles in a very tight formation is not guaranteed) and potentially increased efficiency, different fluids and cases require an adjustment of the CFL coefficients in order to exploit the advantages of the approach and, therefore, the user should be careful in their selection.</p>"},{"location":"4.Code_Overview/","title":"Code overview","text":"<p>The code in this repository contains a serial C++ implementation of the SPH methodology described earlier. The variables associated with the particles' positions, velocities and forces, are stored as members of an object called <code>Fluid</code>, while the methods of another class called <code>SphSolver</code> perform the steps of the algorithm.</p>"},{"location":"4.Code_Overview/#files","title":"Files","text":"<p>The <code>src</code> directory comprises five <code>*.cpp</code> files and their corresponding header (<code>*.h</code>) files, as well as the files to build the code.</p> <ul> <li><code>src/SPH-main.cpp</code> : Contains the source code of the main program which is responsible for instrumenting the execution of the SPH simulation.</li> <li><code>src/initial_conditions.{h, cpp}</code> : Contains the functions which are required in order to create the initial conditions.</li> <li><code>src/main_prog_func.h</code> : Header file for the declarations of the main program functions.</li> <li><code>src/particles.{h, cpp}</code> : Contains a class describing the positions and velocities of particles.</li> <li><code>src/fluid.{h, cpp}</code>  : Contains a class which extends the functionality described in the <code>src/particles.{h, cpp}</code> to represent a cluster of particles which form a fluid.</li> <li><code>src/sph_solver.{h, cpp}</code> : Contains a class which manifests the implementation of the SPH methodology described in this project.</li> <li><code>src/CMakeLists.txt</code> : Contains the instructions to compile the code.</li> </ul>"},{"location":"4.Code_Overview/#reading-inputs","title":"Reading Inputs","text":"<p>The program expects the parameters which are specified in the <code>exec/input</code> directory. When the function <code>initialise()</code> is invoked by the main program to read the <code>.txt</code> files, the <code>&lt;boost/program_options.hpp&gt;</code> library is utilised. This library facilitates the mapping of these parameters to their corresponding values, which are then stored in their respective variable maps in the <code>retrieveInputsFromFile()</code> function. This approach enhances the flexibility and robustness of the input reading process. Users can specify input parameters in the <code>.txt</code> files in any order, provided they are presented as <code>key = value</code> pairs.</p> <pre><code>/* **************************** SPH_main.cpp **************************** */\n\nvoid initialise(std::unique_ptr&lt;Fluid&gt;&amp; fluidPtr, SphSolver&amp; sphSolver) {\n  // Process to obtain the inputs provided by the user\n  po::options_description desc(\"Allowed options\");\n  desc.add_options()(\"init_condition\", po::value&lt;std::string&gt;(),\n                     \"take an initial condition\")(\"T\", po::value&lt;double&gt;(),\n                                                  \"take integration time\")(\n      \"dt\", po::value&lt;double&gt;(), \"take time-step\")(\n      \"coeffCfl1\", po::value&lt;double&gt;(), \"take lamda nu\")(\n      \"coeffCfl2\", po::value&lt;double&gt;(), \"take lamda f\")(\n      \"adaptive_timestep\", po::value&lt;bool&gt;(),\n      \"take flag for adaptive time-step\")(\"h\", po::value&lt;double&gt;(),\n                                          \"take radius of influence\")(\n      \"gas_constant\", po::value&lt;double&gt;(), \"take gas constant\")(\n      \"density_resting\", po::value&lt;double&gt;(), \"take resting density\")(\n      \"viscosity\", po::value&lt;double&gt;(), \"take viscosity\")(\n      \"acceleration_gravity\", po::value&lt;double&gt;(), \"take acc due to gravity\")(\n      \"coeff_restitution\", po::value&lt;double&gt;(), \"take coeff of restitution\")(\n      \"left_wall\", po::value&lt;double&gt;(), \"take left wall position\")(\n      \"right_wall\", po::value&lt;double&gt;(), \"take right wall position\")(\n      \"bottom_wall\", po::value&lt;double&gt;(), \"take bottom wall position\")(\n      \"top_wall\", po::value&lt;double&gt;(), \"take top wall position\")(\n      \"length\", po::value&lt;double&gt;(), \"take length of the block\")(\n      \"width\", po::value&lt;double&gt;(), \"take width of the block\")(\n      \"radius\", po::value&lt;double&gt;(), \"take radius of the droplet\")(\n      \"n\", po::value&lt;int&gt;(), \"take number of particles\")(\n      \"center_x\", po::value&lt;double&gt;(), \"take center of the particle mass in x\")(\n      \"center_y\", po::value&lt;double&gt;(), \"take center of the particle mass in y\")(\n      \"init_x_1\", po::value&lt;double&gt;(), \"take x_1\")(\n      \"init_y_1\", po::value&lt;double&gt;(), \"take y_2\")(\n      \"init_x_2\", po::value&lt;double&gt;(), \"take x_2\")(\n      \"init_y_2\", po::value&lt;double&gt;(), \"take y_2\")(\n      \"init_x_3\", po::value&lt;double&gt;(), \"take x_3\")(\n      \"init_y_3\", po::value&lt;double&gt;(), \"take y_3\")(\n      \"init_x_4\", po::value&lt;double&gt;(), \"take x_4\")(\n      \"init_y_4\", po::value&lt;double&gt;(), \"take y_4\")(\n      \"output_frequency\", po::value&lt;int&gt;(),\n      \"take frequency that output will be written to file\");\n  ...\n\n  icCase = caseVm[\"init_condition\"].as&lt;std::string&gt;();\n  std::string fileName = icCase + \".txt\";\n  retrieveInputsFromFile(fileName, icCase, desc, icVm);\n\n  handleInputErrors(caseVm, domainVm, constantsVm, icVm);\n  ...\n}\n\n\nvoid retrieveInputsFromFile(const std::string&amp; fileName,\n                            const std::string&amp; icCase,\n                            const po::options_description&amp; desc,\n                            po::variables_map&amp; vm) {\n  std::ifstream caseFile;\n  std::string errorMessage = \"Error opening file: \" + fileName;\n  if (fileName == icCase + \".txt\") {\n    errorMessage +=\n        \" Make sure that the value of the init_condition in the case.txt \"\n        \"file is one of the following: ic-one-particle, ic-two-particles, \"\n        \"ic-three-particles, ic-four-particles, ic-droplet, ic-block-drop.\";\n  }\n  // Try to open the file\n  try {\n    caseFile.open(\"../input/\" + fileName);\n    // Throw an exception if the file cannot be opened\n    if (!caseFile.is_open()) {\n      throw std::runtime_error(errorMessage);\n    }\n    po::store(po::parse_config_file(caseFile, desc), vm);\n  } catch (std::runtime_error&amp; e) {\n    // Handle the exception by printing the error message and exiting the\n    // program\n    std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;\n    exit(1);\n  }\n  po::notify(vm);\n}\n</code></pre> <p>Additionally, using the <code>handleInputErrors()</code> function, error handling is integrated into the input file reading process to guarantee that the provided values conform to the constraints imposed by the underlying mathematical models and the physical meaning of each variable. For example, if the user attempts to set a negative value for the timestep, or a value that is greater than the integration time, the program will throw an error and instruct the user to choose a more suitable value.</p> <pre><code>/* **************************** SPH_main.cpp **************************** */\n\nvoid handleInputErrors(const po::variables_map&amp; caseVm,\n                       const po::variables_map&amp; domainVm,\n                       const po::variables_map&amp; constantsVm,\n                       const po::variables_map&amp; icVm) {\n  try {\n    // Error handling for the total integration time\n    if (caseVm[\"T\"].as&lt;double&gt;() &lt;= 0) {\n      throw std::runtime_error(\n          \"Error: Total integration time must be positive!\");\n      // Error handling for the time step\n    } else if (caseVm[\"dt\"].as&lt;double&gt;() &lt;= 0 or\n               caseVm[\"dt\"].as&lt;double&gt;() &gt; caseVm[\"T\"].as&lt;double&gt;()) {\n      throw std::runtime_error(\n          \"Error: Time step must be positive and lower than the total \"\n          \"integration time!\");\n      // Error handling for the output frequency\n    } else if (caseVm[\"output_frequency\"].as&lt;int&gt;() &lt;= 0 or\n               caseVm[\"output_frequency\"].as&lt;int&gt;() &gt;\n                   ceil(caseVm[\"T\"].as&lt;double&gt;() / caseVm[\"dt\"].as&lt;double&gt;())) {\n      throw std::runtime_error(\n          \"Error: Output frequency must be positive and lower than the total \"\n          \"number of iterations!\");\n      // Error handling for the CFL coefficients\n    } else if (caseVm[\"coeffCfl1\"].as&lt;double&gt;() &lt;= 0 or\n               caseVm[\"coeffCfl1\"].as&lt;double&gt;() &gt;= 1 or\n               caseVm[\"coeffCfl2\"].as&lt;double&gt;() &lt;= 0 or\n               caseVm[\"coeffCfl2\"].as&lt;double&gt;() &gt;= 1) {\n      throw std::runtime_error(\n          \"Error: The CFL coefficients must be positive and less than 1\");\n      // Error handling for the domain boundaries\n    } else if (domainVm[\"left_wall\"].as&lt;double&gt;() &gt;=\n                   domainVm[\"right_wall\"].as&lt;double&gt;() ||\n               domainVm[\"bottom_wall\"].as&lt;double&gt;() &gt;=\n                   domainVm[\"top_wall\"].as&lt;double&gt;()) {\n      throw std::runtime_error(\n          \"Error: Please adjust your domain boundaries so that left_wall &lt; \"\n          \"right wall and bottom_wall &lt; top_wall.\");\n      // Error handling for the number of particles\n    } else if (icVm[\"n\"].as&lt;int&gt;() &lt;= 0) {\n      throw std::runtime_error(\"Error: Number of particles must be positive!\");\n    }\n  } catch (std::runtime_error&amp; e) {\n    // Handle the exception by printing the error message and exiting the\n    // program\n    std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;\n    exit(1);\n  }\n}\n</code></pre>"},{"location":"4.Code_Overview/#class-initialisation","title":"Class Initialisation","text":"<p>The code makes use of three different classes which are purposed to represent the fluid and the SPH algorithm deployed in this project. </p> <p>Firstly, one <code>SphSolver</code> object and one pointer to a <code>Fluid</code> object are declared in the main program. The pointer declaration is used for the <code>Fluid</code>, because to initialise the object properly the number of particles is required in the user defined constructor and this information is not yet available since the input files have not been read. These objects are passed as a reference to the <code>initialise()</code> function.</p> <p>Once the input values are read and stored, the provided initial condition (IC) is used to determine the number of particles. This means that although the user has already provided a number of particles, this is just an indication, since the IC (droplet and block drop) require specific formation and the particles to be distributed uniformly. These two conditions cannot be satisfied simultaneously by any number of particles and therefore several adjustments need to be made. The functions <code>closestIntegerSqrt()</code> and <code>rectangleN()</code> from <code>initial_conditions.h</code> are functions suitable for this purpose.</p> <p>The IC functions are called within the <code>setInitialConditions()</code> function and a reference to the pointer of the fluid object is passed as an argument*, as well as the updated number of particles. Inside these functions the user defined constructor of the <code>Fluid</code> class is called and the memory allocation process for the object's containers is invoked. In this, the containers are declared as <code>new</code> raw pointers to arrays, dynamically allocating memory proportional to the number of particles. The function used to initialise the <code>Fluid</code> class for the simple cases of 1,2,3 and 4 particles is demonstrated below.</p> <p>* The rationale behind passing the pointer to the fluid object as a reference is identical to the reason an object is passed as a reference to a function. In these functions we are allocating new memory that the pointer should point to. If the pointer was passed by value (<code>Fluid *fluidPtr</code>) then a copy of the pointer would be pointing to the new memory and our original fluid pointer will still be a <code>nullptr</code>. Of course, since the allocation is happening inside the function, the caller is responsible to <code>delete</code> the object manually.</p> <pre><code>/* **************************** initial_conditions.cpp **************************** */\n\nvoid icBasic(std::unique_ptr&lt;Fluid&gt; &amp;fluidPtr, int nbParticles,\n             std::vector&lt;double&gt; &amp;positionX, std::vector&lt;double&gt; &amp;positionY) {\n  fluidPtr = std::make_unique&lt;Fluid&gt;(nbParticles);\n\n  for (int i = 0; i &lt; nbParticles; i++) {\n    fluid.setPositionX(i, positionX[i]);\n    fluid.setPositionY(i, positionY[i]);\n    fluid.setVelocityX(i, 0.0);\n    fluid.setVelocityY(i, 0.0);\n  }\n}\n</code></pre> <p>Inside the <code>setInitialConditions()</code> function, an <code>std::map</code> object is used to map the initial condition case with a fixed number of particles to their corresponding number of particles, to avoid the use of multiple <code>if</code> statements and make the code cleaner. Then, the initial condition case is set based on the user's input, including additional error handling for the input parameters specific to the selected IC. The workflow for the droplet case is demonstrated below.</p> <pre><code>/* **************************** SPH_main.cpp **************************** */\n\nvoid setInitialConditions(const std::string&amp; icCase,\n                          std::unique_ptr&lt;Fluid&gt;&amp; fluidPtr,\n                          const po::variables_map&amp; icVm,\n                          const po::variables_map&amp; domainVm) {\n  // Fixed nbParticles ic cases map\n  std::map&lt;std::string, int&gt; initConditionToParticlesMap = {\n      {\"ic-one-particle\", 1},\n      {\"ic-two-particles\", 2},\n      {\"ic-three-particles\", 3},\n      {\"ic-four-particles\", 4}};\n\n  // Get the number of particles based on the ic case (for the more complex ic)\n  int nbParticles;\n  if (icCase == \"ic-droplet\" || icCase == \"ic-block-drop\") {\n    nbParticles = icVm[\"n\"].as&lt;int&gt;();\n  } else {\n    nbParticles = initConditionToParticlesMap[icCase];\n  }\n\n  // Block of code ...\n\n  } else if (icCase == \"ic-droplet\") {\n    // Get the droplet radius and center coordinates from the ic file\n    double radius = icVm[\"radius\"].as&lt;double&gt;();\n    // Error handling for the droplet radius\n    try {\n      if (radius &lt;= 0) {\n        throw std::runtime_error(\"Error: Radius must be positive!\");\n      }\n    } catch (std::runtime_error&amp; e) {\n      // Handle the exception by printing the error message and exiting the\n      // program\n      std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;\n      exit(1);\n    }\n    double centerX = icVm[\"center_x\"].as&lt;double&gt;();\n    double centerY = icVm[\"center_y\"].as&lt;double&gt;();\n    // Error handling for the droplet initial position (centerX, centerY)\n    try {\n      if (centerX - radius &lt; domainVm[\"left_wall\"].as&lt;double&gt;() ||\n          centerX + radius &gt; domainVm[\"right_wall\"].as&lt;double&gt;() ||\n          centerY - radius &lt; domainVm[\"bottom_wall\"].as&lt;double&gt;() ||\n          centerY + radius &gt; domainVm[\"top_wall\"].as&lt;double&gt;()) {\n        throw std::runtime_error(\n            \"Error: The droplet must be within the domain boundaries! Please \"\n            \"adjust the center coordinates.\");\n      }\n    } catch (std::runtime_error&amp; e) {\n      // Handle the exception by printing the error message and exiting the\n      // program\n      std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;\n      exit(1);\n    }\n    icDroplet(fluidPtr, nbParticles, radius, centerX, centerY);\n  } else {\n    std::cerr &lt;&lt; \"Error: Initial condition function not found! Make sure \"\n              &lt;&lt; \"that the value of the init_condition in the case.txt file is \"\n              &lt;&lt; \"one of the following: ic-one-particle, ic-two-particles, \"\n              &lt;&lt; \"ic-three-particles, ic-four-particles, ic-droplet, \"\n              &lt;&lt; \"ic-block-drop.\" &lt;&lt; std::endl;\n    exit(1);\n  }\n}\n</code></pre> <p>Finally, after the object initialisation, the rest of the parameters which are required by the <code>SphSolver</code> and the <code>Fluid</code> objects are being set with the use of setter functions, the Neighbour Searching grid is created, the initialised particles are placed in their corresponding grid cells, and their neighbours are identified.</p> <pre><code>/* **************************** SPH_main.cpp **************************** */\n\n// void initialise(fluid** fluidPtr, SphSolver&amp; sphSolver) { ...\n\n// Set the parameters of the solver for the specific simulation\nsphSolver.setTimestep(caseVm[\"dt\"].as&lt;double&gt;());\nsphSolver.setAdaptiveTimestep(caseVm[\"adaptive_timestep\"].as&lt;bool&gt;());\nsphSolver.setCflCoefficients(caseVm[\"coeffCfl1\"].as&lt;double&gt;(),\n                              caseVm[\"coeffCfl2\"].as&lt;double&gt;());\nsphSolver.setTotalTime(caseVm[\"T\"].as&lt;double&gt;());\nsphSolver.setOutputFrequency(caseVm[\"output_frequency\"].as&lt;int&gt;());\nsphSolver.setCoeffRestitution(constantsVm[\"coeff_restitution\"].as&lt;double&gt;());\nsphSolver.setLeftWall(domainVm[\"left_wall\"].as&lt;double&gt;());\nsphSolver.setRightWall(domainVm[\"right_wall\"].as&lt;double&gt;());\nsphSolver.setTopWall(domainVm[\"top_wall\"].as&lt;double&gt;());\nsphSolver.setBottomWall(domainVm[\"bottom_wall\"].as&lt;double&gt;());\nsphSolver.setPrecalculatedValues(constantsVm[\"h\"].as&lt;double&gt;());\n\n// Define the fluid based on the inputs\nfluidPtr-&gt;setRadInfl(constantsVm[\"h\"].as&lt;double&gt;());\nfluidPtr-&gt;setGasConstant(constantsVm[\"gas_constant\"].as&lt;double&gt;());\nfluidPtr-&gt;setDensityResting(constantsVm[\"density_resting\"].as&lt;double&gt;());\nfluidPtr-&gt;setViscosity(constantsVm[\"viscosity\"].as&lt;double&gt;());\nfluidPtr-&gt;setAccelerationGravity(\n    constantsVm[\"acceleration_gravity\"].as&lt;double&gt;());\n\n// Calculate the mass of the particles\nsphSolver.createGrid(*fluidPtr);\nsphSolver.neighbourParticlesSearch(*fluidPtr);\nstd::vector&lt;std::vector&lt;std::pair&lt;int, double&gt;&gt;&gt; neighboursPerParticle =\n    sphSolver.getNeighbourParticles();\nfluidPtr-&gt;calculateMass(neighboursPerParticle);\n</code></pre>"},{"location":"4.Code_Overview/#output-files","title":"Output files","text":"<p>The output files are initialised by the function <code>initOutputFiles()</code>, after the <code>Fluid</code> class initialisation and before the time integration procedure is invoked. This is done because during the time integration, the code will produce runtime outputs and therefore the corresponding files need to have been created beforehand. The outputs are exported in <code>.csv</code> format which displays good readability and facilitates data manipulation compared to <code>.txt</code> files. They are stored in a centralised location, specifically within the <code>/exec/output/</code> directory. This centralisation simplifies data organisation and retrieval, making it easier for users to access and analyse output data.</p> <p>Upon successful execution, the program generates two types of files:</p> <ul> <li> <p>Energies File: This file, containing Total, Kinetic, and Potential energies, is updated at each timestep. The results can be visualized by using the script <code>post/plot_energies.py</code>.</p> </li> <li> <p>Particle Positions File: This file captures the positions of the particles at a given timestep, and it can be visualized using the scripts <code>post/visualize_particles.py</code>.</p> </li> </ul> <pre><code>/* **************************** SPH_main.cpp **************************** */\n\nvoid storeToFile(Fluid &amp;fluid, std::string type, std::ofstream &amp;targetFile,\n                 double currentIntegrationTime) {\n  if (type == \"energy\") {\n    // Write energies in the Energy-File\n    targetFile &lt;&lt; currentIntegrationTime &lt;&lt; \",\" &lt;&lt; fluid.getKineticEnergy()\n               &lt;&lt; \",\" &lt;&lt; fluid.getPotentialEnergy() &lt;&lt; \",\"\n               &lt;&lt; fluid.getPotentialEnergy() + fluid.getKineticEnergy() &lt;&lt; \"\\n\";\n  } else if (type == \"position\") {\n    // Write positions in the position file\n    for (size_t k = 0; k &lt; fluid.getNumberOfParticles(); k++) {\n      targetFile &lt;&lt; currentIntegrationTime &lt;&lt; \",\" &lt;&lt; fluid.getPositionX(k)\n                 &lt;&lt; \",\" &lt;&lt; fluid.getPositionY(k) &lt;&lt; \"\\n\";\n    }\n  }\n}\n</code></pre> Energy plots (left) and initial position (right) for a droplet of 60 particles."},{"location":"4.Code_Overview/#time-integration","title":"Time integration","text":"<p>Following the initialisation of the class and the output files, the function <code>SphSolver::timeIntegration()</code> is invoked. Within this function, the steps of the SPH algorithm are executed, and the outputs are exported.</p> <pre><code>/* ***************************** SPH-main.cpp ****************************** */\n\n// Time integration loop\nsphSolver.timeIntegration(*sphFluid, simulationPositionsFile,\n                          finalPositionsFile, energiesFile);\n\n/* **************************** sph_solver.cpp **************************** */\n\nvoid SphSolver::timeIntegration(Fluid &amp;data,\n                              std::ofstream &amp;simulationPositionsFile,\n                              std::ofstream &amp;finalPositionsFile,\n                              std::ofstream &amp;energiesFile) {\n  std ::cout &lt;&lt; \"Time integration started -- OK\"\n              &lt;&lt; \"\\n\";\n\n  while (currentIntegrationTime &lt; totalTime) {\n    if (adaptiveTimestepBool) {\n      // Reset the adaptive timestep related variables\n      maxVelocity = 0.0;\n      maxAcceleration = 0.0;\n    }\n\n    // In each iteration the distances between the particles are recalculated,\n    // as well as their density and pressure\n    neighbourParticlesSearch(data);\n    data.calculateDensity(neighbourParticles);\n    data.calculatePressure();\n    particleIterations(data);\n\n    currentIntegrationTime += dt;\n\n    if (t % outputFrequency == 0) {\n      storeToFile(data, \"energy\", energiesFile, currentIntegrationTime);\n\n      storeToFile(data, \"position\", simulationPositionsFile, currentIntegrationTime);\n    }\n\n    t++;\n\n    if (adaptiveTimestepBool) {\n      adaptiveTimestep(data);\n    }\n  }\n  // Store particles' positions after integration is completed\n  storeToFile(data, \"position\", finalPositionsFile, currentIntegrationTime);\n\n  std ::cout &lt;&lt; \"Time integration finished -- OK\"\n              &lt;&lt; \"\\n\";\n}\n</code></pre>"},{"location":"4.Code_Overview/#implementation-of-the-sph-algorithm","title":"Implementation of the SPH algorithm","text":"<p>The steps of the SPH algorithm are executed by the function <code>SphSolver::timeIntegration()</code> and are implemented as follows.</p>"},{"location":"4.Code_Overview/#density","title":"Density","text":"<p>The density of the fluid associated with each particle  is approximated as:</p> <pre><code>/* **************************** fluid.cpp **************************** */\nvoid Fluid::calculateDensity(\n  const std::vector&lt;std::vector&lt;std::pair&lt;int, double&gt;&gt;&gt;&amp; neighbours) {\n  double phi, normalisedDistance, normalisedDistanceSqr;\n\n  for (size_t i = 0; i &lt; nbParticles; i++) {\n    density[i] = mass * fourPih2;\n    for (size_t j = 0; j &lt; neighbours[i].size(); j++) {\n      normalisedDistance = neighbours[i][j].second * hInverse;\n      normalisedDistanceSqr = (1.0 - normalisedDistance * normalisedDistance);\n      phi = fourPih2 * normalisedDistanceSqr * normalisedDistanceSqr *\n            normalisedDistanceSqr;\n      density[i] += mass * phi;\n    }\n  }\n}\n</code></pre> <p>where:</p> <ul> <li><code>mass</code> is the mass of a particle ().</li> <li><code>phi</code> is the kernel density function for density ().</li> <li><code>normalisedDistance</code> is the distance between particle  and particle , normalised by the interaction radius ().</li> <li><code>hInverse</code> is the inverse of the interaction radius () which is constant throughout the simulation and is calculated once and stored in a variable.</li> </ul>"},{"location":"4.Code_Overview/#pressure","title":"Pressure","text":"<p>The pressure is calculated based on the ideal gas law</p> <pre><code>/* **************************** fluid.cpp **************************** */\n\nvoid Fluid::calculatePressure() {\n  for (size_t i = 0; i &lt; nbParticles; i++) {\n    pressure[i] = gasConstant * (density[i] - densityResting);\n  }\n}\n</code></pre> <p>where:</p> <ul> <li><code>densityResting</code> is the fluid's resting density (). </li> <li><code>gasConstant</code> is the gas constant ().</li> </ul>"},{"location":"4.Code_Overview/#pressure-force","title":"Pressure force","text":"<p>The force exerted on the particle due to pressure from neighboring fluid particles is calculated as</p> <pre><code>/* **************************** sph_solver.cpp **************************** */\n\ndouble SphSolver::calculatePressureForce(Fluid &amp;data,\n                                         std::function&lt;double(int)&gt; getPosition,\n                                         int particleIndex) {\n  double sum = 0.0;  // Initializing the summation\n  double normalisedDistance;\n  double position = getPosition(particleIndex);\n  double pressure = data.getPressure(particleIndex);\n  double mass = data.getMass();\n  double radiusOfInfluence = data.getRadInfl();\n  size_t neighbourIndex;\n\n  for (size_t j = 0; j &lt; neighbourParticles[particleIndex].size(); j++) {\n    neighbourIndex = neighbourParticles[particleIndex][j].first;\n    if (particleIndex != neighbourIndex) {\n      try {\n        normalisedDistance =\n            neighbourParticles[particleIndex][j].second / radiusOfInfluence;\n        // Throw an exception if a singularity is about to appear\n        if (normalisedDistance == 0.0) {\n          throw std::runtime_error(\n              \"A singularity appeared. Consider reducing the number of \"\n              \"particles or increasing the initial distance between the \"\n              \"particles.\");\n        }\n      } catch (std::runtime_error &amp;e) {\n        // Handle the exception by printing the error message and exiting the\n        // program\n        std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;\n        exit(1);\n      }\n\n      sum += (mass / data.getDensity(neighbourIndex)) *\n             ((pressure + data.getPressure(neighbourIndex)) / 2.0) *\n             (thirtyPih3 * (position - getPosition(neighbourIndex))) *\n             (((1.0 - normalisedDistance) * (1.0 - normalisedDistance)) /\n              normalisedDistance);\n    }\n  }\n  return -sum;\n}\n</code></pre> <p>Where:</p> <ul> <li><code>thirtyPih3</code> is a constant precalculated value () which assists in the calculation of the nabla of the kernel density function for pressure .</li> <li><code>pressure</code> is the pressure of the  particle.</li> <li><code>data.getPressure(neighbourIndex)</code> is used to retrieve the pressure of the neighbouring  particle.</li> <li><code>data.getDensity(neighbourIndex)</code> is used to retrieve the density of the neighbouring  particle.</li> </ul> <p>It is important to note that the function admits as an argument the <code>std::function&lt;double(int)&gt; getPosition</code> which is a pointer to a function of the <code>Fluid</code> class. This is done because the <code>SphSolver::calculatePressureForce()</code> function needs to be called twice for each particle - once for the x component and once for the y component of the pressure force.</p> <pre><code>forcePressureX = calculatePressureForce(data, ptrGetPositionX, i);\n\nforcePressureY = calculatePressureForce(data, ptrGetPositionY, i);\n</code></pre> <p>In this way, the function for the calculation of pressure forces remains generic and direction agnostic which means that we do not have to duplicate any piece of code.</p> <p>Also, in this function, an error handling occurs, to check whether a singularity appears if two particles come very close to each other. This would make the normalized distance nearly zero and <code>NaN</code> values would appear in the code. Herein we choose to inform the users about that incident and advise them to adjust the case parameters in order to avoid such behaviour.</p>"},{"location":"4.Code_Overview/#viscous-force","title":"Viscous force","text":"<p>The force acting on each particle due to viscous effects is calculated as</p> <pre><code>/* **************************** sph_solver.cpp **************************** */\n\ndouble SphSolver::calcViscousForce(Fluid &amp;data,\n                                   std::function&lt;double(int)&gt; getVelocity,\n                                   int particleIndex) {\n  double sum = 0.0;  // Initializing the summation\n  double normalisedDistance;\n  double velocity = getVelocity(particleIndex);\n  double mass = data.getMass();\n  double radiusOfInfluence = data.getRadInfl();\n  size_t neighbourIndex;\n\n  for (size_t j = 0; j &lt; neighbourParticles[particleIndex].size(); j++) {\n    neighbourIndex = neighbourParticles[particleIndex][j].first;\n\n    if (particleIndex != neighbourIndex) {\n      normalisedDistance =\n          neighbourParticles[particleIndex][j].second / radiusOfInfluence;\n      sum += (mass / data.getDensity(neighbourIndex)) *\n             (velocity - getVelocity(neighbourIndex)) *\n             (fourtyPih4 * (1.0 - normalisedDistance));\n    }\n  }\n\n  return -data.getViscosity() * sum;\n}\n</code></pre> <p>Where:</p> <ul> <li><code>fourtyPih4</code> is a constant precalculated value () which assists in the calculation of the nabla of the kernel density function for the visocsity ().</li> <li><code>velocity</code> is the velocity of the  particle.</li> <li><code>getVelocity(neighbourIndex)</code> is used to retrieve the velocity of the neighbouring  particle.</li> </ul> <p>For the reasons explained for <code>SphSolver::calculatePressureForce()</code>, a pointer to a function is required as an argument.</p>"},{"location":"4.Code_Overview/#gravity-force","title":"Gravity force:","text":"<p>Finally, the force due to gravity is calculated as:</p> <pre><code>/* **************************** sph_solver.cpp **************************** */\n\ndouble SphSolver::calcGravityForce(Fluid &amp;data, int particleIndex) {\n  return -data.getDensity(particleIndex) * data.getAccelerationGravity();\n}\n</code></pre> <p>Where:</p> <ul> <li><code>data.getAccelerationGravity()</code> is used to retrieve the value of the acceleration of gravity.</li> </ul>"},{"location":"4.Code_Overview/#acceleration","title":"Acceleration","text":"<p>The acceleration of each particle is calculated as:</p> <pre><code>/* **************************** sph_solver.cpp **************************** */\n\ndouble acceleration = (forcePressure + forceViscous + forceGravity) /\n                        data.getDensity(particleIndex);\n</code></pre>"},{"location":"4.Code_Overview/#time-marching","title":"Time marching","text":"<p>We solve the equation as a function of time by finding the velocity and position of each particle at each of a number of time steps. We denote a property  of particle  at time step  as . The state of the property half way between time steps  and  is denoted as .</p> <p>We begin with the initial conditions of the system, which are the positions and velocities of the particles at time . We iteratively use the state of the system at time step  to find the state of the system at time step  using a leap-frog scheme, which provides improved stability characteristics. For the x-directions we do the following:</p> <pre><code>/* **************************** sph_solver.cpp **************************** */\n\n// x-direction\nnewVelocity = data.getVelocityX(particleIndex) +\n              integrationCoeff *\n                  velocityIntegration(data, particleIndex, forcePressureX,\n                                      forceViscousX, forceGravityX);\ndata.setVelocityX(particleIndex, newVelocity);\n\nnewPosition = data.getPositionX(particleIndex) + newVelocity * dt;\n\ndata.setPositionX(particleIndex, newPosition);\n</code></pre> <p>We normally use <code>integrationCoeff=1.0</code>, but because the velocity is calculated at half-steps, we need to initialise the scheme on the first time step using <code>integrationCoeff=0.5</code>:</p> <pre><code>/* **************************** sph_solver.cpp **************************** */\n\n// First step to initialise the scheme\nif (t == 0) {\n  integrationCoeff = 0.5;\n}\n</code></pre>"},{"location":"5.IO_overview/","title":"C++ Input and Output Management Overview","text":"<p>Effective input and output (I/O) management lies at the heart of robust software programs, ensuring seamless interaction between the user and the application. In the realm of C++ programming, where efficiency and precision are paramount, proper handling of input and output operations holds significant importance. A meticulously designed I/O system not only enhances the user experience by facilitating clear communication but also bolsters program reliability by guarding against errors and unexpected behaviours. This documentation provides an overview of the approaches that were followed to handle the inputs provided to and outputs generated by the program, along with some reasoning on these choices.</p>"},{"location":"5.IO_overview/#input-reading","title":"Input Reading","text":"<p>Initially, we outline the two primary concepts or solutions employed to guarantee proper input management, \"boost program options\" and \"error handling\".</p>"},{"location":"5.IO_overview/#boost-program-options","title":"Boost Program Options","text":"<p>Programs which perform simulations must be able to have the scenario they are simulating specified by the user. However, the user may sometimes provide invalid values as part of this specification. It's desirable to have a system in place that can handle these invalid values and provide the user with a clear message about which values are invalid.</p> <p>In the current program, the Boost Program Options library (<code>&lt;boost/program_options.hpp&gt;</code>) is utilised. Boost Program Options is a powerful C++ library that simplifies the handling of program input. It provides a straightforward and intuitive way to manage command-line arguments, read files, and define options for your C++ programs. This way, it allows focusing on the logic of the program rather than dealing with the complexities of input parsing. Use of this library facilitates the easy reading of user inputs and allows us to provide enhanced definitions of the expected input parameters, accompanied by their types, using the <code>options_description</code> object and its <code>add_options()</code> function.</p> <p>A snippet from the program's code, related to the management of input parameters, is shown below:</p> <pre><code>/* **************************** SPH-main.cpp **************************** */\n\n\n// Process to obtain the inputs provided by the user\npo::options_description desc(\"Allowed options\");\ndesc.add_options()(\"init_condition\", po::value&lt;std::string&gt;(),\n                    \"take an initial condition\")(\"T\", po::value&lt;double&gt;(),\n                                                \"take integration time\")(\n    \"dt\", po::value&lt;double&gt;(), \"take time-step\")(\n    \"coeffCfl1\", po::value&lt;double&gt;(), \"take lamda nu\")(\n    \"coeffCfl2\", po::value&lt;double&gt;(), \"take lamda f\")(\n    \"adaptive_timestep\", po::value&lt;bool&gt;(),\n    \"take flag for adaptive time-step\")(\"h\", po::value&lt;double&gt;(),\n                                        \"take radius of influence\")(\n    \"gas_constant\", po::value&lt;double&gt;(), \"take gas constant\")(\n    \"density_resting\", po::value&lt;double&gt;(), \"take resting density\")(\n    \"viscosity\", po::value&lt;double&gt;(), \"take viscosity\")(\n    \"acceleration_gravity\", po::value&lt;double&gt;(), \"take acc due to gravity\")(\n    \"coeff_restitution\", po::value&lt;double&gt;(), \"take coeff of restitution\")(\n    \"left_wall\", po::value&lt;double&gt;(), \"take left wall position\")(\n    \"right_wall\", po::value&lt;double&gt;(), \"take right wall position\")(\n    \"bottom_wall\", po::value&lt;double&gt;(), \"take bottom wall position\")(\n    \"top_wall\", po::value&lt;double&gt;(), \"take top wall position\")(\n    \"length\", po::value&lt;double&gt;(), \"take length of the block\")(\n    \"width\", po::value&lt;double&gt;(), \"take width of the block\")(\n    \"radius\", po::value&lt;double&gt;(), \"take radius of the droplet\")(\n    \"n\", po::value&lt;int&gt;(), \"take number of particles\")(\n    \"center_x\", po::value&lt;double&gt;(), \"take center of the particle mass in x\")(\n    \"center_y\", po::value&lt;double&gt;(), \"take center of the particle mass in y\")(\n    \"init_x_1\", po::value&lt;double&gt;(), \"take x_1\")(\n    \"init_y_1\", po::value&lt;double&gt;(), \"take y_2\")(\n    \"init_x_2\", po::value&lt;double&gt;(), \"take x_2\")(\n    \"init_y_2\", po::value&lt;double&gt;(), \"take y_2\")(\n    \"init_x_3\", po::value&lt;double&gt;(), \"take x_3\")(\n    \"init_y_3\", po::value&lt;double&gt;(), \"take y_3\")(\n    \"init_x_4\", po::value&lt;double&gt;(), \"take x_4\")(\n    \"init_y_4\", po::value&lt;double&gt;(), \"take y_4\")(\n    \"output_frequency\", po::value&lt;int&gt;(),\n    \"take frequency that output will be written to file\");\n</code></pre> <p>Then, as shown in the code snippet below, the code line <code>po::store(po::parse_config_file(icFile, desc), icVm);</code> uses these definitions (<code>desc</code>) to search for matches between the input parsed from the <code>*.txt</code> files in the <code>exec/input/</code> directory (<code>icFile</code> in this case), and the expected parameters. These mapped pairs are finally stored in another object provided by the library, called a <code>variables_map</code> (<code>icVm</code> in this case). This approach enhances the flexibility and robustness of the input reading process. Users can specify input parameters in the <code>txt</code> files in any order, provided they are given as <code>key = value</code> pairs.</p> <pre><code>/* **************************** SPH-main.cpp **************************** */\n\nvoid retrieveInputsFromFile(const std::string&amp; fileName,\n                            const std::string&amp; icCase,\n                            const po::options_description&amp; desc,\n                            po::variables_map&amp; vm) {\n  std::ifstream caseFile;\n  std::string errorMessage = \"Error opening file: \" + fileName;\n  if (fileName == icCase + \".txt\") {\n    errorMessage +=\n        \" Make sure that the value of the init_condition in the case.txt \"\n        \"file is one of the following: ic-one-particle, ic-two-particles, \"\n        \"ic-three-particles, ic-four-particles, ic-droplet, ic-block-drop.\";\n  }\n  // Try to open the file\n  try {\n    caseFile.open(\"../input/\" + fileName);\n    // Throw an exception if the file cannot be opened\n    if (!caseFile.is_open()) {\n      throw std::runtime_error(errorMessage);\n    }\n    po::store(po::parse_config_file(caseFile, desc), vm);\n  } catch (std::runtime_error&amp; e) {\n    // Handle the exception by printing the error message and exiting the\n    // program\n    std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;\n    exit(1);\n  }\n  po::notify(vm);\n}\n</code></pre> <p>Note that the <code>exit(1)</code> means the program as a whole returns an exit code of <code>1</code>. An exit code of 0 conventionally means a program has exited successfully, with other values indicating an error.  As a result, returning <code>1</code> in the case of an error is useful for scripts or other programs that may call this program, as they can check the exit code and take appropriate action if the program has failed.</p>"},{"location":"5.IO_overview/#error-handling","title":"Error Handling","text":"<p>Another crucial part of reading input by a program is error handling. In order for the program to run without errors, the provided input must conform to the program's specific rules, e.g., in the current case, the constraints imposed by the underlying mathematical models and the physical meaning of each variable. However, in the case of reading input from <code>*.txt</code> files, there is no way to guarantee that the user will adhere to these rules. For example, if the user attempts to set a negative value for the timestep, or a value that is greater than the integration time, the program will crash.</p> <p>Even though we cannot control the user's actions, we can - and we should always - control our program's response to these actions. A program that simply crashes on unexpected input is not user-friendly, since it does not provide any guidance to the user regarding their wrong input. Error handling is the process of properly handling this \"bad\" input, so that the program provides information to the user regarding the reason of the error or the correct usage of the program, before it normally exits.</p> <p>In C++, exceptions provide suitable functionality for input error handling. With exceptions, we can add <code>try</code>/<code>catch</code> blocks to our program. The <code>try</code> part should include the error-prone code, which in the case of handling input could be either the proper opening of the file (e.g., <code>icFile.is_open()</code>) or a condition that checks that the input value adheres to the program's rules (e.g., <code>caseVm[\"dt\"].as&lt;double&gt;() &lt;= 0</code>). In case of non-expected behaviour, a <code>throw</code> statement is used, which throws an exception. There are numerous types of exceptions, such as the <code>runtime_error</code> exception thrown in the code snipped below, accompanied by an intuitive error message. Finally, the exception thrown in the <code>try</code> block, is caught in the <code>catch</code> block. In other words, the <code>catch</code> block performs the \"handling\" of the error, and this is where our code for the desired behaviour in case of an error should be included. For instance, in the following code snipped, when the <code>runtime_error</code> exception is caught, the program prints the corresponding error message, in order to guide the user regarding the correct usage, and then exits in a controlled manner.</p> <pre><code>/* **************************** SPH-main.cpp **************************** */\n\nvoid handleInputErrors(const po::variables_map&amp; caseVm,\n                       const po::variables_map&amp; domainVm,\n                       const po::variables_map&amp; constantsVm,\n                       const po::variables_map&amp; icVm) {\n  try {\n    // Error handling for the total integration time\n    if (caseVm[\"T\"].as&lt;double&gt;() &lt;= 0) {\n      throw std::runtime_error(\n          \"Error: Total integration time must be positive!\");\n      // Error handling for the time step\n    } else if (caseVm[\"dt\"].as&lt;double&gt;() &lt;= 0 or\n               caseVm[\"dt\"].as&lt;double&gt;() &gt; caseVm[\"T\"].as&lt;double&gt;()) {\n      throw std::runtime_error(\n          \"Error: Time step must be positive and lower than the total \"\n          \"integration time!\");\n      // Error handling for the output frequency\n    } else if (caseVm[\"output_frequency\"].as&lt;int&gt;() &lt;= 0 or\n               caseVm[\"output_frequency\"].as&lt;int&gt;() &gt;\n                   ceil(caseVm[\"T\"].as&lt;double&gt;() / caseVm[\"dt\"].as&lt;double&gt;())) {\n      throw std::runtime_error(\n          \"Error: Output frequency must be positive and lower than the total \"\n          \"number of iterations!\");\n      // Error handling for the CFL coefficients\n    } else if (caseVm[\"coeffCfl1\"].as&lt;double&gt;() &lt;= 0 or\n               caseVm[\"coeffCfl1\"].as&lt;double&gt;() &gt;= 1 or\n               caseVm[\"coeffCfl2\"].as&lt;double&gt;() &lt;= 0 or\n               caseVm[\"coeffCfl2\"].as&lt;double&gt;() &gt;= 1) {\n      throw std::runtime_error(\n          \"Error: The CFL coefficients must be positive and less than 1\");\n      // Error handling for the domain boundaries\n    } else if (domainVm[\"left_wall\"].as&lt;double&gt;() &gt;=\n                   domainVm[\"right_wall\"].as&lt;double&gt;() ||\n               domainVm[\"bottom_wall\"].as&lt;double&gt;() &gt;=\n                   domainVm[\"top_wall\"].as&lt;double&gt;()) {\n      throw std::runtime_error(\n          \"Error: Please adjust your domain boundaries so that left_wall &lt; \"\n          \"right wall and bottom_wall &lt; top_wall.\");\n      // Error handling for the number of particles\n    } else if (icVm[\"n\"].as&lt;int&gt;() &lt;= 0) {\n      throw std::runtime_error(\"Error: Number of particles must be positive!\");\n    }\n  } catch (std::runtime_error&amp; e) {\n    // Handle the exception by printing the error message and exiting the\n    // program\n    std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;\n    exit(1);\n  }\n}\n</code></pre> <p>In a different case, we could also decide that we do not want our program to exit at all, but replace the wrong input with the closest appropriate value instead. For instance, in the <code>ic-droplet</code> required a square grid of particles. The functions <code>closest_integer_sqrt()</code> (declared in <code>initial_conditions.h</code>)  is used to transform <code>nbParticles</code> to a value with an integer square root. For instance, if a user requested 50 particles, 49 particles would be used instead as this could be formed by a 7x7 grid of particles.</p> <p>Similarly for the <code>ic-block-drop</code> initial condition case a rectangular grid of particles is required. <code>rectangleN()</code> (also declared in <code>initial_conditions.h</code>) we make sure that the input value is transformed to the closest value that can be used to create a rectangle of the user-provided dimensions. This could be also seen as a type of error handling, since, if left unhandled, the program would either result in an error or wrong output.</p> <p>In all cases, it is crucial that we provide error handling for the values of all the different input parameters expected by the program. This allows errors in the input to be corrected, or highlight the error to the user before the program ends in an error.</p>"},{"location":"5.IO_overview/#output-generation","title":"Output Generation","text":"<p>Having briefly outlined how inputs are managed, we will now offer an overview of how the program generates and handles its outputs.</p>"},{"location":"5.IO_overview/#csv-data-storage","title":"CSV Data Storage","text":"<p>The data generated by the SPH application are ultimately stored in CSV text files. Storing data in widely usable file types, such as CSV (Comma-Separated Values), is crucial for software programs due to its interoperability and accessibility across various platforms and applications. CSV files offer a standardised format that can be easily imported and exported by different software tools, databases, and programming languages. This ensures seamless data exchange and integration between different components of a system, facilitating collaboration and interoperability among developers and users.</p> <p>Furthermore, CSV files are human-readable and editable using simple text editors, making them ideal for sharing and manipulating data without requiring specialised software. This accessibility simplifies data management tasks and empowers users to work with the data directly, fostering transparency and efficiency in data-driven processes. By prioritising the use of widely usable file types like CSV, software programs can enhance their usability, flexibility, and compatibility across diverse computing environments.</p>"},{"location":"5.IO_overview/#output-management-essentials","title":"Output Management Essentials","text":"<p>Ensuring that the correct paths exist before attempting to store program output is crucial for maintaining the integrity and reliability of the software. By verifying and creating necessary directories as needed, while also initialising files appropriately, using the correct variable type for the solution, developers can prevent errors and interruptions during the output storage process. Closing files when no longer needed further enhances system resource management, ensuring optimal performance and data integrity within the C++ programming environment.</p> <p>In this program, we begin the output generation operations by ensuring that the target output location exists. The <code>createDirectory()</code> function, provided below, first checks whether the target folder path exists, and if not, it creates it.</p> <pre><code>/* **************************** SPH-main.cpp **************************** */\n\n\nvoid createDirectory(std::string folderPath) {\n  // Check if the target folder already exists\n  if (!std::filesystem::exists(folderPath)) {\n    // Create target folder\n    std::filesystem::create_directories(folderPath);\n  }\n}\n</code></pre> <p>This sets the foundation for the creation of the output files themselves. These files are initialised using the <code>std::ofstream</code> variable type. Such type offers a straightforward and intuitive interface for file operations in C++. For example, it allows for writing data to files using the familiar stream insertion operator <code>&lt;&lt;</code> just like you would write to <code>std::cout</code>. Moreover, it comes with a <code>destructor</code>, that takes care of the release of the used resources when appropriate (including if an error occurs elsewhere in the code), eliminating the need for manual handling of such operations.</p> <pre><code>/* **************************** SPH-main.cpp **************************** */\n\n\nstd::tuple&lt;std::ofstream, std::ofstream, std::ofstream, std::ofstream&gt;\ninitOutputFiles(const std::string &amp;outputFolder) {\n  // Create the output folder if it doesn't exist\n  createDirectory(outputFolder);\n\n  // Declare and initialise the output files\n  std::ofstream initialPositions(outputFolder + \"/initial-positions.csv\",\n                                 std::ios::out | std::ios::trunc);\n  std::ofstream simulationPositions(outputFolder + \"/simulation-positions.csv\",\n                                    std::ios::out | std::ios::trunc);\n  std::ofstream finalPositions(outputFolder + \"/final-positions.csv\",\n                               std::ios::out | std::ios::trunc);\n  std::ofstream energies(outputFolder + \"/energies.csv\",\n                         std::ios::out | std::ios::trunc);\n\n  initialPositions &lt;&lt; std::fixed &lt;&lt; std::setprecision(5);\n  initialPositions &lt;&lt; \"Timestamp,Position_X,Position_Y\"\n                   &lt;&lt; \"\\n\";\n\n...\n</code></pre> <p>This application exports data to CSV files based on a user-defined intervals in simulation time, specified within the <code>/exec/input/case.txt</code> input file. This approach allows the program to minimise memory usage by writing data in intervals, preventing unnecessary resource consumption and ensuring smooth operation even with large datasets. Additionally, less frequent exporting reduces interruptions for write operations, enhancing program responsiveness and user experience. Ultimately, this user-controlled export frequency strikes a balance between data granularity and resource efficiency, adapting to diverse project needs and system constraints.</p>"},{"location":"6.OOP_Concepts/","title":"Object-Oriented Programming","text":"<p>Object-oriented programming (OOP) is a style of programming adopted by many programming languages (e.g. C++,Java, Python). It allows developers to create a user-defined data type known as a class. A user may create instances of these classes, known as objects, and use them to store and manipulate data. The contents of the class will define the data that is stored in instances of the class in member variables, and member functions which can access, manipulate, and perform calculations on the data.</p> <p>A class can be very simple, such as a variable type (i.e. integer, double, array etc.) or very complex, such as a solver for non-linear problems. Every class comprises several components which are the data members, the member functions, the constructors and the destructor.</p>"},{"location":"6.OOP_Concepts/#inheritance","title":"Inheritance","text":"<p>Depending on the application, a developer can create families of objects which usually have conceptual dependency and coherence among them. A class-family consists of a base class and its derived classes, which may further have their own subclasses. The base class serves as a representation of a general concept, such as a \"human\" with attributes like name, age, and height. The derived classes, in turn, embody more specific instances of that concept. For example, a child class might represent a \"student\" with additional attributes like grades and the number of extracurricular activities. These supplementary details, which may be irrelevant when characterizing another type of human, such as a retired professional, are encapsulated as member variables within the student class. The process of deriving a new child class based on a base class is called inheritance.</p>"},{"location":"6.OOP_Concepts/#object-orientation-in-the-sph-solver","title":"Object orientation in the SPH solver","text":"<p>In this project we chose object orientation which is widely supported by C++ in order to facilitate the implementation of the SPH algorithm and exploit all the benefits that accompany the use of OOP. The basic design idea is built around three classes.</p>"},{"location":"6.OOP_Concepts/#class-particles","title":"Class <code>Particles</code>","text":"<p>The first class is used to represent the building blocks of the SPH approach, which are the particles. A particle, however, is not only relevant in the context of SPH, but it can also be used in other applications such as in the representation of multiphase flows where the particles can be droplets whose motion is two-way coupled with a carrier gas phase. Therefore, the <code>Particles</code> class was decided to be kept as simple (and generic) as possible and to encapsulate only the information which can be applicable to every application that incorporates the use of cluster of particles. Therefore, the members of the \"particles\" class are only related to the particles' positions and velocities.</p> <p>It is important to emphasize that an instance of the <code>Particles</code> class contains data pertaining to all the particles involved in the simulation (and therefore represents the entirety of the cluster), rather than information exclusive to a single particle.</p> <pre><code>/* **************************** particles.h **************************** */\nclass Particles {\n\n  ...\n\n protected:\n  unsigned int nbParticles;  // number of particles and characteristic size of\n                             // the class arrays\n\n  // Positions\n  std::vector&lt;double&gt; positionX;\n  std::vector&lt;double&gt; positionY;\n\n  // Velocities\n  std::vector&lt;double&gt; velocityX;\n  std::vector&lt;double&gt; velocityY;\n\n  std::vector&lt;double&gt; particleSpeedSq;  // u(i)^2+v(i)^2\n\n\n};\n</code></pre> <p>The particles class is initialised in the \"user defined constructor\" by using the number of particles (<code>nb_particles</code>) which is required to determine the size of the arrays.</p> <pre><code>/* **************************** particles.cpp **************************** */\n\n// User defined constructor\nParticles::Particles(const unsigned nNew)\n    : nbParticles(nNew),\n      positionX(nNew, 0.0),\n      positionY(nNew, 0.0),\n      velocityX(nNew, 0.0),\n      velocityY(nNew, 0.0),\n      particleSpeedSq(nNew, 0.0) {}\n</code></pre>"},{"location":"6.OOP_Concepts/#class-fluid","title":"Class <code>Fluid</code>","text":"<p>A cluster of particles, depending on its behaviour, can represent a variety of concepts. One of these concepts is what we will refer to herein as a \"fluid\", which apart from being discretized in particles also has other attributes such as density, mass and pressure. Therefore, the class <code>Fluid</code> is a child class of the particles class which is extended in order to encapsulate more members to fully characterize the simulated fluid, and its state during every timestep. In the main program the base class will never be invoked explicitly, but only implicitly through the instantiation of a <code>Fluid</code> object. However, from the developer's perspective, using this approach makes the code more modular and allows for the derivation of multiple children from the base class if needed.</p> <pre><code>/* **************************** fluid.h **************************** */\n\nclass Fluid : public Particles {\n\n ...\n\n private:\n // Constants of the problem\n double gasConstant;\n double densityResting;\n double viscosity;\n double accelerationGravity;\n double radiusOfInfluence;\n // Helper member variables\n double hInverse;\n double fourPih2;\n\n // Mass\n double mass = 1.0;\n\n // Density\n std::vector&lt;double&gt; density;\n\n // Pressure\n std::vector&lt;double&gt; pressure;\n\n}\n</code></pre>"},{"location":"6.OOP_Concepts/#class-sphsolver","title":"Class <code>SphSolver</code>","text":"<p>The <code>SphSolver</code> class contains the implementation of the steps of the algorithm described in this project. The main function, which is called by the main program, is the <code>sphSolver::timeIntegration(Fluid &amp;data, std::ofstream &amp;finalPositionsFile, std::ofstream &amp;energiesFile);</code> where the member functions of the class are invoked and perform calculations on the data members of the <code>Fluid</code> object in order to update the positions and the velocities of the particles. Because the members of the <code>Fluid</code> class have been declared either as protected (from the base class) or private, the solver class does not have direct access to its members and therefore the use of <code>setter</code> and <code>getter</code> functions and the overloaded <code>()</code> operator is required. This is a good practice when working with OOP techniques because it promotes the idea of data hiding by the classes, and increases the robustness of the code, since the object's members cannot be directly modified from anywhere in the code, apart from inside the class. This is an example of encapsulation. Below an example on how the <code>Fluid</code> members are manipulated by one of the <code>SphSolver's</code> member functions is presented.</p> <pre><code>/* **************************** sph_solver.cpp **************************** */\n\nvoid SphSolver::updatePosition(Fluid &amp;data, int particleIndex) {\n  double newVelocity;\n  double newPosition;\n  double integrationCoeff = 1.0;\n\n  // First step to initialise the scheme\n  if (t == 0) {\n    integrationCoeff = 0.5;\n  }\n\n  // x-direction\n  newVelocity = data.getVelocityX(particleIndex) +\n                integrationCoeff *\n                    velocityIntegration(data, particleIndex, forcePressureX,\n                                        forceViscousX, forceGravityX);\n  data.setVelocityX(particleIndex, newVelocity);\n\n  newPosition = data.getPositionX(particleIndex) + newVelocity * dt;\n\n  data.setPositionX(particleIndex, newPosition);\n\n  if (adaptiveTimestepBool) {\n    maxVelocity = std::max(maxVelocity, std::abs(newVelocity));\n  }\n\n  // y-direction\n  newVelocity = data.getVelocityY(particleIndex) +\n                integrationCoeff *\n                    velocityIntegration(data, particleIndex, forcePressureY,\n                                        forceViscousY, forceGravityY);\n\n  data.setVelocityY(particleIndex, newVelocity);\n\n  newPosition = data.getPositionY(particleIndex) + newVelocity * dt;\n  data.setPositionY(particleIndex, newPosition);\n\n  if (adaptiveTimestepBool) {\n    maxVelocity = std::max(maxVelocity, std::abs(newVelocity));\n  }\n}\n</code></pre>"},{"location":"7.STL/","title":"Standard Template Library usage","text":"<p>Modern C++ uses the Standard Template Library (STL) which is a library that comprises a lot of algorithms as well as standard containers, most of which have been optimised in the best possible way (though some of them still cause problems). Using these containers and algorithms is good practice. </p> <p>In this code, we could have used C-style arrays and raw pointers. This could be harmless in the case that the code base stays the same and the developers can be sure about their memory management and ownership semantics. But, as the code base expands, it would have been more difficult to track every object, moving from function to function. Instead, to comply with modern C++ practices, we have used <code>std::vector</code> instead of dynamically allocated arrays and <code>std::unique_ptr</code> instead of raw pointers.</p>"},{"location":"7.STL/#stdvector","title":"std::vector","text":"<p>The vector container behind the scenes is simply an array, minus the painful memory management that would be needed if we had used raw arrays. Using vectors can create an overhead since the developer can expand the container by using, for example, the <code>push_back</code> method, but there is a catch. The <code>std::vector</code> allocates a specified space in memory at initialization. If the developer \"pushes\" more objects in it than memory exists, it would need to allocate another space - larger this time - and copy all the elements from one container to the other. As one can imagine, this can create a serious overhead in very large vectors. However, the authors of STL have thought about this case and they have included a pretty handy method called <code>reserve</code>. With <code>reserve</code>, the developer can allocate exactly how much memory the object will need, given that the size is a known quantity. This could relax the constraints about performance hits. </p> <p>Another useful thing about vectors is that they use contiguous memory, meaning each element should be \"side to side\" inside memory. That means that a simple access should give an average of  in terms of time. Since the code base includes a lot of vector access operations, we assessed that this container is the best option for our cases.</p>"},{"location":"7.STL/#stdunique_ptr","title":"std::unique_ptr","text":"<p>Smart pointers were an addition to the STL in order to avoid the need for manual memory allocation for an object and then (and most crucially) manual deallocation of its resources. Smart pointers are part of a C++ programming technique called Resource Acquisition Is Initialization (RAII) which binds the lifetime of a resource that must be acquired before use (like memory on the heap) to the lifetime of an object. What this means is that the smart pointer is only valid once it's in scope. Once it goes out of scope, all of its resources are properly freed. This way the developer can be sure about proper memory management. There are several smart pointers (namely <code>std::shared_ptr</code>, <code>std::unique_ptr</code> and <code>std::weak_ptr</code>) but here we will discuss <code>std::unique_ptr</code> since this is the one used in our code base and is by far the most commonly used elsewhere.</p> <p>We used <code>std::unique_ptr</code> wherever there was a need for a pointer in the code base. There's nothing wrong with using a raw pointer, but raw pointers shouldn't handle ownership, meaning a raw pointer is good enough only when it doesn't own anything (i.e passing it to a function which does some calculations).</p> <p>One thing that stands out for <code>std::unique_ptr</code> is that it cannot be copied. That means that the ownership of the managed resource needs to be transferred to a new object if the developer wants to move the pointer. The original object will no longer own the resource and the original <code>std::unique_ptr</code> will contain a <code>nullptr</code>. To create a <code>std::unique_ptr</code> it is good practice to use <code>std::make_unique</code> as can be seen in the snippet below:</p> <pre><code>auto fluidPtr = std::make_unique&lt;Fluid&gt;(nbParticles);\n</code></pre> <p>After this the user can use <code>fluidPtr</code> as they would use a raw pointer, with the difference being that they don't (and shouldn't) delete the pointer at the end of the scope.</p>"},{"location":"8.Efficient_Programming/","title":"Good practices for computational efficiency","text":"<p>The complexity of the SPH algorithm requires the code implementation to display good computational performance in order for the program to be able to handle cases involving large numbers of particles. In this project we apply several standard good practices to avoid unnecessary computations or accesses to memory locations, thus achieving reasonable and useful execution time. It is good practice to apply such optimisations and techniques without compromising the memory usage, readability and future maintenance of the code, and always to balance the trade-off between these three.</p>"},{"location":"8.Efficient_Programming/#optimisation-flags","title":"Optimisation flags","text":"<p>Optimisation flags are compiler directives (introduced in the Makefile) that instruct the compiler to apply various optimisations when translating high-level source code (in this case C++ code) into machine code (the binary executable). These flags are essential tools for improving the performance and efficiency of a program. Common optimisation flags, such as <code>-O1</code>, <code>-O2</code>, or <code>-O3</code> in GCC and Clang, enable different levels of optimisation, ranging from basic to more aggressive transformations. These optimisations include inlining functions, constant folding, dead code elimination, loop unrolling, and many others. In practice, judicious use of optimisation flags, coupled with profiling tools, allows for fine-tuning of the code for optimal performance while maintaining a balance between speed and other considerations.</p>"},{"location":"8.Efficient_Programming/#properly-arranged-for-loops","title":"Properly arranged <code>for</code> loops","text":"<p>To effectively organize nested <code>for</code> loops, it's essential to grasp the underlying workings of the operating system when executing a program coded in C++.</p> <p>Dynamically allocated containers such as <code>arrays</code> or <code>std::vectors</code>, make use of consecutive blocks of memory on the heap in order to store their data. Upon accessing elements within these containers, the program checks if the data are present in the cache (a small amount of memory on the processor). If the data is not in the cache, it needs to fetch the data from memory. Accessing data from the cache is significantly faster than fetching it from memory, providing a performance improvement. But what makes some data available on the cache and some other not?</p> <p>When requesting information for a specific address in the memory, the hardware cache management retrieves large chunks of data (the one requested and its neighbouring data that might be used soon) known as cache lines. This is based on the principle of spatial locality, which suggests that if a particular piece of data is accessed, there's a high probability that nearby data will be accessed soon. By loading these cache lines, the system takes advantage of spatial locality and ensures that potentially needed data is readily available, reducing the need to fetch data from the slower main memory during runtime.</p> <p>To leverage this functionality, the nested <code>for</code> loops can be organized to facilitate faster access to the next entry of the array. When the outer loop iterates over the <code>i</code> elements and the nested loop iterates over the <code>j</code> elements (i * elements + j), this arrangement increases the chances of accessing elements that are already in the cache line. This optimisation makes the program cache-friendly, resulting in greater performance. In simpler terms, by structuring the loops to access nearby elements in memory, the program becomes more efficient and runs faster.</p> <pre><code>void Fluid::calculateDensity() {\ndouble phi, normalisedDistance, normalisedDistanceSqr;\n\n// find \u03c6\nfor (size_t i = 0; i &lt; nbParticles; i++) {\n  density[i] = 0.0;\n\n  for (size_t j = 0; j &lt; nbParticles; j++) {\n    normalisedDistance = distanceQ[i * nbParticles + j] =\n        std::abs(distance[i * nbParticles + j] * hInverse);\n\n    normalisedDistanceSqr = (1.0 - normalisedDistance * normalisedDistance);\n    if (normalisedDistance &lt; 1.0) {\n      phi = fourPih2 * normalisedDistanceSqr * normalisedDistanceSqr *\n            normalisedDistanceSqr;\n\n    } else {\n      phi = 0.0;\n    }\n\n    density[i] += mass * phi;\n  }\n}\n}\n</code></pre>"},{"location":"8.Efficient_Programming/#pre-calculated-values","title":"Pre-calculated values","text":"<p>The algorithm provides the equations which describe the calculations to be performed during one iteration. However, when we transfer the algorithm in a code, some of the equations have constant parts (either throughout the whole simulation or throughout a timestep), and these do not need to be re-calculated every time the code reaches the corresponding algorithmic step. It is the developer's responsibility to identify these calculations and pre-calculate all such values. A demonstration of this concept in our SPH code is the calculation of the pressure force. A somewhat naive implementation of this step (on branch <code>v2</code> in the repository of the project) would be:</p> <pre><code>double SphSolver::calculatePressureForce(Fluid &amp;data,\n                                        std::function&lt;double(int)&gt; getPosition,\n                                        int particleIndex) {\ndouble sum = 0.0;  // Initializing the summation\ndouble radiusOfInfluence = data.getRadInfl();\ndouble thirtyPih3 =\n    (-30.0 / (M_PI * radiusOfInfluence * radiusOfInfluence *\n              radiusOfInfluence));  // Precalculated value used to avoid\n                                    // multiple divisions and multiplications\n\nfor (int j = 0; j &lt; numberOfParticles; j++) {\n  if (particleIndex != j) {\n    if (data.getDistanceQ(particleIndex * numberOfParticles + j) &lt; 1.0) {\n      sum +=\n          (data.getMass() / data.getDensity(j)) *\n          ((data.getPressure(particleIndex) + data.getPressure(j)) / 2.0) *\n          (thirtyPih3 * (getPosition(particleIndex) - getPosition(j))) *\n          (((1.0 - data.getDistanceQ(particleIndex * numberOfParticles + j)) *\n            (1.0 -\n              data.getDistanceQ(particleIndex * numberOfParticles + j))) /\n            data.getDistanceQ(particleIndex * numberOfParticles + j));\n    }\n  }\n}\nreturn -sum;\n}\n</code></pre> <p>In the above piece of code there is an attempt to pre-calculate some values by defining the <code>double thirtyPih3</code>. However, not only are there a lot more things to be improved, but this specific optimisation could be achieved in a better way. More specifically, this value is constant throughout the entire simulation, since none of its components change at runtime. It is therefore better practice to define it as a data member of the <code>SphSolver</code> class and calculate it only once during the initialization process.</p> <pre><code>// Assign values to pre-calculated values\ninline void setPrecalculatedValues(double radiusOfInfluence) {\n  thirtyPih3 = -30.0 / (M_PI * std::pow(radiusOfInfluence, 3.0));\n\n  fourtyPih4 = 40.0 / (M_PI * std::pow(radiusOfInfluence, 4.0));\n}\n</code></pre> <p>In addition, we can identify several values which can be stored as local variables within the scope of the function and be used in the <code>j</code> loop, instead of invoking the getter functions of the <code>Fluid</code> class for every <code>j</code>. As we saw earlier, there is a possible overhead associated with calling a function and accessing elements in an array or vector, and this practice helps us alleviate it. Finally, since the iterations are performed on the <code>j</code> index, there is a constant value in the index of <code>data.getDistanceQ(particleIndex * numberOfParticles + j)</code> which is the <code>particleIndex * numberOfParticles</code> and this can also be pre-calculated and stored as a function variable. Finally, the above function has taken the following form:</p> <pre><code>double SphSolver::calculatePressureForce(Fluid &amp;data,\n                                      std::function&lt;double(int)&gt; getPosition,\n                                      int particleIndex) {\ndouble sum = 0.0;  // Initializing the summation\ndouble normalisedDistance;\ndouble position = getPosition(particleIndex);\ndouble pressure = data.getPressure(particleIndex);\ndouble mass = data.getMass();\nint index = particleIndex * numberOfParticles;\n\nfor (int j = 0; j &lt; numberOfParticles; j++) {\n  if (particleIndex != j) {\n    normalisedDistance =\n        data.getDistanceQ(index + j);  // Store this variable to avoid\n                                      // multiple calls of the get function\n    if (normalisedDistance &lt; 1.0) {\n      sum += (mass / data.getDensity(j)) *\n            ((pressure + data.getPressure(j)) / 2.0) *\n            (thirtyPih3 * (position - getPosition(j))) *\n            (((1.0 - normalisedDistance) * (1.0 - normalisedDistance)) /\n              normalisedDistance);\n    }\n  }\n}\nreturn -sum;\n}\n</code></pre> <p>One may notice that the repeated operation <code>1.0 - normalisedDistance</code> was not replaced. However, this is part of the trade-off, balancing readability with performance. This would require creating a new variable with a name such as <code>oneMinusNormDistance</code> and setting a value for this variable at every iteration, in order to avoid a single subtraction. The computational saving is likely negligible (if not none) and the code readability would have been compromised. By looking at the updated version of the pressure force calculation function, although this is not always the case, one may notice that apart from accelerating the code, its readability in this case has improved drastically.</p>"},{"location":"8.Efficient_Programming/#inlined-functions","title":"Inlined functions","text":"<p>Inlining functions in C++ is a compiler optimisation technique where the compiler replaces the function call with the actual body of the function at the call site. This eliminates the overhead of the function call itself, leading to potentially faster execution. Inlining is particularly useful for small, frequently called functions, as it reduces the function call overhead and can result in more efficient code. However, it is important to note that inlining is usually associated with small functions because the use for larger functions can lead to an increased size of the generated code which requires more memory and larger compiling times. Additionally, inlining can facilitate further optimisations by providing the compiler with opportunities for constant folding, dead code elimination, and other performance enhancements. Prudent use of inline functions, particularly for small, performance-critical code sections, can contribute to more efficient and streamlined C++ programs. In our code, we made use of the <code>inline</code> keyword for all the getter and setter functions which are small and qualify for this usage. This indicates that the compiler is instructed (but not forced) to inline theses functions.</p> <pre><code>// Function to get the density felt by a single particle\ninline double getDensity(int index) { return density[index]; }\n</code></pre>"},{"location":"A1.Code_Execution/","title":"Compiling and executing the SPH-SOLVER","text":"<p>The list of requirements for the source code is:</p> <ul> <li>A <code>C++20</code> version</li> <li>The <code>Boost</code> library</li> </ul> <p>To compile the code, the user has to change the working directory to <code>exec/build</code> and then run the following instructions in the terminal:</p> <pre><code>cmake ../../src\n</code></pre> <p>and then:</p> <pre><code>cmake --build .\n</code></pre> <p>This produces an executable file, called <code>SPH-SOLVER</code>, in the <code>exec/build</code> folder. To execute the code, the user needs to run the following:</p> <pre><code>./SPH-SOLVER\n</code></pre> <p>To clean the <code>build</code> directory, the user can use the following command:</p> <pre><code>cmake --build . --target clean\n</code></pre> <p>This will effectively delete the binary from the <code>build</code> directory.</p>"},{"location":"A1.Code_Execution/#setting-up-a-case","title":"Setting up a case","text":"<p>This program can simulate a range of different scenarios. To set up a case to be run, the user has to set the parameters of the problem by using the <code>.txt</code> files in the <code>exec/input</code> directory. These files specify a number of parameters of the problem. Each line of each file contains the name of the parameter being set, an equals sign, then the value of the parameter. Optionally, these lines may contain comments beginning with <code>#</code> characters, which are ignored by the code.</p> <p>In <code>case.txt</code> the user can specify the type of initial condition, which specifies the initial configuration of particles. The initial condition (IC) can be one of the following</p> <ul> <li> <p>A single particle (<code>ic-one-particle</code>) : to test the correctness of time integration and gravity forcing, as well as the bottom boundary condition.</p> </li> <li> <p>Two particles (<code>ic-two-particles</code>) : to assess the pressure force and viscous terms.</p> </li> <li> <p>Three particles (<code>ic-three-particles</code>) : to assess left and right boundary conditions.</p> </li> <li> <p>Four particles (<code>ic-four-particles</code>) : to assess multiple particle interaction.</p> </li> <li> <p>A Block drop (<code>ic-block-drop</code>): a grid of particles occupying a rectangular region.</p> </li> <li> <p>A Droplet (<code>ic-droplet</code>): particles occupying a circular region.</p> </li> </ul> <p>After selecting the desired IC, the user has to specify its parameters (number and position of the particles) in the homonymous to the IC <code>.txt</code> file. The domain is rectangular and two-dimensional with corners which have coordinates that can be specified in <code>domain.txt</code>. Finally, the constant parameters of the problem which characterize the fluid and the solver set-up can be specified in <code>constants.txt</code>.</p> <p>The different input files each require different parameters to be set. These are:</p> <ul> <li><code>case.txt</code> defines the simulation configuration:</li> <li>initial condition : <code>init_condition</code>  (see above for options)</li> <li>simulation time (s) : <code>T</code></li> <li>time-step (s) : <code>dt</code></li> <li>adaptive timestep flag : <code>adaptive_timestep</code></li> <li>CFL coefficient 1 : <code>coeffCfl1</code></li> <li>CFL coefficient 2 : <code>coeffCfl2</code></li> <li>-output frequency : <code>output_frequency</code></li> <li> <p><code>constants.txt</code> defines physical constants:</p> </li> <li> <p>radius of influence (m) : <code>h</code></p> </li> <li>gas constant (J/kg/K) : <code>gas_constant</code></li> <li>resting density (kg/m) : <code>density_resting</code></li> <li>viscosity (Pa s) : <code>viscosity</code></li> <li>acceleration due to gravity (m/s) : <code>acceleration_gravity</code></li> <li>coefficient of restitution : <code>coeff_restitution</code></li> <li><code>domain.txt</code>: defines the dimensions of the domain utilised in the simulation</li> </ul> <p>In addition, depending on the initial condition selected, one of the following files is required:</p> <ul> <li><code>ic-one-particle.txt</code>: sets the initial positions when the selected initial condition is \"ic-one-particle\"</li> <li><code>ic-{two, three, four}-particles.txt</code>: sets the initial positions for the corresponding cases</li> <li><code>ic-block-drop.txt</code>: sets initial conditions for SPH, including the number of particles, the length and width of the block, and the initial axes positions for the center of the block</li> <li><code>ic-droplet.txt</code>: sets initial conditions for SPH, including the number of particles, the size of the radius of the droplet, and the initial axes positions for the center of the droplet</li> </ul>"},{"location":"A2.GH_Codespaces/","title":"GitHub Codespaces","text":"<p>GitHub Codespaces provides you with a cloud-based development environment directly within a GitHub repository. It comes pre-configured with popular tools and extensions, offering a ready-to-code set up.</p> <p>There are various benefits of using GitHub (GH) codespaces, among which are consistency as it ensures that all developers work in an identical environment, preventing set up issues, and accessibility by allowing you to work from anywhere with a browser and internet connection. A potential benefit could be the scalability that it provides, as more powerful machines are available for computationally intensive SPH simulations.</p> <p>In this project, it makes it easier for the user to run the SPH solver, as it is pre-configured with the necessary tools and extensions. This allows the user to focus on the development of the SPH solver and the execution of the code, without having to worry about the environment set up. You may still download the repository and run the code on your local machine, but the GH codespaces environment is a convenient alternative.</p>"},{"location":"A2.GH_Codespaces/#how-to-use-github-codespaces","title":"How to Use GitHub Codespaces","text":"<ol> <li>In the ReCoDE-SPH-solver-2D-NS GitHub repository, navigate to the \"Code\" tab</li> <li>Locate the green \"Code\" button and click on it. You should see something like the following:</li> </ol> <ol> <li>Click on the + sign or the green \"Create codespace on main\" button to create a new codespace that is based on the code of the main branch. If you would like to target a different branch, target a different region or select the type of machine to use for the new codespace, you can click on the three-dots (\u00b7\u00b7\u00b7) to open the options menu and select \"New with options...\", as shown in the following image:</li> </ol> <p>Then, you will be presented with the following page, allowing you to customise the codespace set up:</p> <p></p> <ol> <li>When you proceed with the creation of a GH codespace, you are presented with the following screen, displaying the codespace building progress:</li> </ol> <p></p> <ol> <li>After the Codespace has been built, you are located within a cloud-based IDE that contains the repository's code. An integrated terminal session is open by default within the codespace, allowing you to run commands in this environment. This page is a VS Code-like interface.</li> </ol> <p></p> <p>The ReCoDE-SPH-solver-2D-NS repository has been configured with a <code>devcontainer.json</code> file that defines a custom development environment with specific tools, extensions, and configurations. This is necessary to enable the user to run the commands to execute the SPH program developed in this repository. This container references a <code>Dockerfile</code>, which provides the actual instructions for the environment set up.</p> <p>The <code>devcontainer.json</code> used for this repository is simple:</p> <pre><code>{\n    \"name\": \"sph_solver\",\n    \"build\": {\n        \"dockerfile\": \"../Dockerfile.dev\"\n    }\n}\n</code></pre> <p>It is located within a directory named <code>.devcontainer</code>.</p>"},{"location":"A2.GH_Codespaces/#management","title":"Management","text":"<p>You can manage the available codespaces by selecting the \"Manage codespaces\" option from the menu in the \"Code\" tab of the repository:</p> <p></p> <p>You will be presented with a list of the currently available GH Codespaces for this repository. From here, you can perform various actions, such as renaming or stopping the codespace, changing the machine type, opening the application on a browser, and more.</p> <p></p>"},{"location":"A3.Profiling/","title":"Profiling and timing","text":""},{"location":"A3.Profiling/#background","title":"Background","text":"<p>Profiling a program is a vital step when attempting to optimise its function, and was used in the development of this program. In order to make decisions regarding different algorithms and containers to be used, the developers profiled successive iterations of the codebase to identify bottlenecks and to check changes to the code had improved performance instead of degrading it. <code>valgrind</code> and <code>perf</code>, and Linux <code>time</code> command were among the tools used.</p>"},{"location":"A3.Profiling/#valgrind","title":"Valgrind","text":"<p>Valgrind is an instrumentation framework that can be used to detect memory leaks, memory corruption, and undefined memory usage in C and C++ programs. It achieves this by running the program in a virtual environment and monitoring the memory operations. Valgrind provides several tools, including Memcheck (for memory debugging), Cachegrind (for cache profiling), and Callgrind (for call graph profiling). Callgrind is a Valgrind tool designed to profile the call structure of a program. It collects information about the functions called, the number of instructions executed in each function, and the call relationships between functions. This information can be used to identify performance bottlenecks and optimize the code. </p>"},{"location":"A3.Profiling/#usage","title":"Usage","text":"<ol> <li> <p>Installation:</p> <p>Make sure Valgrind is installed on your system. You can typically install it using your package manager on Linux systems. <pre><code>sudo apt-get install valgrind   # For Debian/Ubuntu\n</code></pre></p> </li> <li> <p>Include the -g compiler flag in the Cmake file</p> <p>The use of the <code>-g</code> compiler flag, which includes debugging symbols in the binary, should be included in the <code>Cmake</code>. The debugging symbols enhance the information available to Valgrind during its analysis.</p> </li> <li> <p>Run your program with Callgrind:</p> <p>To profile your program with Callgrind, use the following command: <pre><code>valgrind --tool=callgrind &lt;executable&gt;\n</code></pre></p> </li> <li> <p>Analyze the output:</p> <p>After running the program, Valgrind will generate a callgrind.out.\\ file (where \\ is the process ID of your program). You can analyze this file using the <code>kcachegrind</code> tool, which provides a graphical user interface for exploring the profiling data. <pre><code>kcachegrind callgrind.out.&lt;pid&gt;\n</code></pre> <p>In MacOS, the user can use <code>qcachegrind</code> to analyze the output and see which of the functions consume most of the resources. The output should be similar to the one in the picture below:</p> Output of the <code>qcachegrind</code>. <p>In  the image the user can see that the functions provide a percentage of CPU usage throughout the lifetime of the execution, so any bottlenecks are easily identifiable.</p>"},{"location":"A3.Profiling/#perf","title":"Perf","text":"<p><code>perf</code> is a powerful performance analysis tool in Linux that provides a wide range of features for profiling and analyzing the performance of programs. It allows you to collect and analyze various performance-related data, such as CPU usage, memory access patterns, and more.</p>"},{"location":"A3.Profiling/#usage_1","title":"Usage","text":"<ol> <li> <p>Installation:</p> <p>You can install perf on most Linux systems using your package manager.</p> <pre><code>sudo apt-get install linux-tools-common   # For Debian/Ubuntu\n</code></pre> </li> <li> <p>Basic Usage:</p> <p>To collect performance data for a program, you can use the following basic command:</p> <p><pre><code>perf record -g -p &lt;pid&gt;   # Record performance data for a running process\n</code></pre> or, for a command: <pre><code>perf record -g &lt;executable&gt;   # Record performance data for a specific command\n</code></pre> The <code>-g</code> option captures call-graph information, which is essential for creating flame graphs.</p> </li> <li> <p>Flamegraphs:</p> <p>Flamegraphs are a visualization technique for profiling data that provides a detailed and intuitive representation of where time is spent in your code. They can be generated from <code>perf</code> data using tools like <code>FlameGraph</code>.</p> <ol> <li> <p>Install Flamegraph:</p> <p>Clone the FlameGraph repository from GitHub. <pre><code>git clone https://github.com/brendangregg/FlameGraph.git\n</code></pre></p> </li> <li> <p>Generate Flamegraph:</p> <p>Use the <code>stackcollapse-perf.pl</code> script to convert the <code>perf</code> data into a format suitable for flame graphs, and then use <code>flamegraph.pl</code> to generate the actual flame graph.</p> <p><pre><code>perf script | FlameGraph/stackcollapse-perf.pl | FlameGraph/flamegraph.pl &gt; flamegraph.svg\n</code></pre> This command reads the <code>perf script</code> output, collapses the stack frames, and generates a flame graph in SVG format.</p> </li> <li> <p>View Flamegraph:</p> <p>Open the generated SVG file (<code>flamegraph.svg</code>) in a web browser to explore the flame graph visually. The width of each box in the graph represents the proportional time spent in each function. An example is shown below (unfortunately Github doesn't allow interactive <code>.svg</code> with scripts due to exploits like XSS attacks, so the image below is not interactive as it would be in a local browser):</p> Flamegraph for v3. </li> </ol> </li> </ol>"},{"location":"A3.Profiling/#timing","title":"Timing","text":"<p>In order to validate that the changes provided a significant decrease in execution time, the developers also measured the time of execution for a variety of cases. To time the execution the Linux command <code>time</code> was used. The results of <code>time</code> are usually of the given format: <pre><code>real    0m1.806s\nuser    0m1.805s\nsys     0m0.000s\n</code></pre></p> <ul> <li><code>real</code>:  Refers to the actual elapsed time from the start to the finish of the command's execution. This is the \"wall-clock\" time, including any time spent waiting for external resources(e.g. disk I/O, network operations or waiting for other processes)</li> <li><code>user</code>: Refers to the amount of CPU time spent executing the code within the process itself while in user mode. This means the time the CPU dedicated to running the program's instructions</li> <li><code>sys</code>: Refers to the amount of CPU time the process spent in kernel mode. This is the time the CPU spends executing system calls on behalf of the processes, such as file operations, memory management or system services.</li> </ul>"},{"location":"A3.Profiling/#usage_2","title":"Usage","text":"<p>The <code>time</code> command is fairly straightforward to execute: <pre><code>time &lt;executable&gt;\n</code></pre></p>"},{"location":"A3.Profiling/#sph-code-results","title":"SPH code results","text":""},{"location":"A3.Profiling/#cpu-time","title":"CPU time","text":""},{"location":"A3.Profiling/#inter-version-comparison","title":"Inter-version comparison","text":"<p>The performance of the code for a various number of particles can be seen in the figure bellow.</p> CPU time vs number of particles for the three different versions of the code. The scatter points mark the measurements and the lines represent the fitted functions. <p>The project went through multiple iterations which are stored in different branches of the repository. The three lines correspond to v2-v4 in increasing performance. The \"C style arrays unoptimized\" version displays the worst computational performance, because although it uses C style arrays which are considered to introduce a smaller overhead compared to <code>std::vectors</code>, most of the optimizations which were described in the previous sections had not been applied yet. Therefore, it is evident that an implementation of good performance related practices can allow to overcome the computational drawbacks which may arise from creating a safer and more robust code. </p> <p>The final version of the code (\"Reduced algorithmic complexity optimized\") improves the performance of the code from  to . This gain in computational performance becomes extremely important as the number of particles grows and makes it possible to simulate cases with very large numbers of particles, which were not feasible before. This highlights the fact that the most important factor in the computational performance of a scientific code is the complexity of the underlying algorithm and this should be the first consideration when conceptualizing a scientific program.</p>"},{"location":"A3.Profiling/#optimization-compiler-flags-ofast","title":"Optimization compiler flags (-Ofast)","text":"<p>In the following figure, the importance of using the proper optimization compiler flags is displayed.</p> CPU time vs number of particles for the comparison of versions before and after the use of optimization flags. The scatter points mark the measurements and the lines represent the fitted functions. <p>Both cases display an important computational gain upon using the compiler flags with the largest number of particles shown here. However, it is interesting to notice how the \"std:vectors optimized - optimization flags\" version is consistently outperforming all the other cases for the full range of number of particles, while this is not the case for its counterpart where optimization flags were not used. This case performs worse for small numbers of particles, and it is only in the case of 1600 particles that it outperforms both the \"C style arrays unoptimized\" versions. Nevertheless, a typical SPH application is likely to incorporate very large numbers of particles and therefore the use of optimization compiler flags is recommended in any case.</p>"},{"location":"A3.Profiling/#flamegraphs","title":"Flamegraphs","text":""},{"location":"A3.Profiling/#results-for-the-final-version-of-the-code","title":"Results for the final version of the code","text":"<p>The Flamegraph of the final version of the code is displayed bellow.</p> Flamegraph for the final version of the code. <p>Comparing this flamegraph with the one displayed earlier we can notice the huge impact of the efficient neighbour searching on the computational behaviour of the code. In the earlier versions, most of the CPU time was mainly spent on the calculation of the viscous and pressure forces, and the inter-particle distance calculations. On the contrary, in the final version of the code, most of the CPU time is spent on the neighbour searching algorithm whose complexity is smaller than the earlier inter-particle distance calculation procedure (!). Therefore, not only did the introduction of this feature decrease the time which was devoted for the neighbour searching, but also it helped to eliminate the computational burden that was imposed by the calculation of the pressure and viscous forces.</p>"},{"location":"A3.Profiling/#interpreting-the-flamegraphs","title":"Interpreting the flamegraphs","text":"<p>Flamegraphs are a great tool for assisting the design process of optimization strategies. In this case, we can conclude that probably spending more time in optimizing the force calculation functions would be pointless, and our attention should focus mostly on the neighbour searching procedure. While on the contrary, if we were to use the older versions of the code, our decision would be different.</p> <p>One typical strategy for reducing the computational cost of scientific codes, is to parallelize them by using domain decomposition. However, by advising the latter flamegraph we may conclude that fully parallelizing the code may be too elaborate and probably not useful. One good starting point could be to just parallelize the interfacing of the particles and the neighbour searching function, as these are mainly the code's bottlenecks.</p>"},{"location":"A4.Post_Analysis/","title":"Post-processing","text":"<p>This document compiles the descriptions and usage instructions for several Python scripts used to visualise the results of an SPH simulation. These scripts analyse and present data captured during the simulation, providing insights into particle movement, energy dynamics, and adaptive timestep evolution.</p> <p>There are 3 different post simulation scripts:</p> <ol> <li>visualise_particles.{py,ipynb}</li> <li>plot_energies.{py, ipynb}</li> <li>simulation_animation.{py, ipynb}</li> </ol>"},{"location":"A4.Post_Analysis/#1-position-visualisation","title":"1. Position Visualisation","text":"<p>The visualise_particles.{py, ipynb} script generates scatter plots visualising the initial and final positions of particles in an Smoothed Particle Hydrodynamics simulation. The script extracts data from CSV files and uses the simulation boundaries defined in a separate domain file to create informative plots.</p> <p>The script uses two Python modules; the pandas module to read the position data from the CSV files they are stored in and the matplotlib module to create and display the visualisations of the initial and final positions of the particles.</p> Output of the visualise_particles.{py, ipynb} scripts: Snapshot of the initial positions of the particles for a droplet case."},{"location":"A4.Post_Analysis/#usage","title":"Usage:","text":"<ul> <li>Ensure you have the following libraries installed in your Python environment: pandas, matplotlib.</li> <li>Run the script from the command line, using the command <code>python visualise_positions.py.</code>, or run it as a Jupyter notebook, by executing the notebook cells of the <code>visualise_positions.ipynb</code> file.</li> </ul>"},{"location":"A4.Post_Analysis/#inputs","title":"Inputs:","text":"<ul> <li>CSV files containing particle position data. These files must have Position_X and Position_Y columns.</li> <li>Domain file (domain.txt) specifying the simulation boundaries using keyword-value pairs (e.g., left_wall: 0.0).</li> </ul>"},{"location":"A4.Post_Analysis/#outputs","title":"Outputs:","text":"<p>Separate scatter plots displaying the initial and final particle positions.</p>"},{"location":"A4.Post_Analysis/#assumptions","title":"Assumptions:","text":"<ul> <li>The expected CSV file format is consistent with Position_X and Position_Y columns.</li> <li>The domain file uses the specified keyword-value format for defining boundaries.</li> </ul>"},{"location":"A4.Post_Analysis/#2-energy-plots","title":"2. Energy Plots","text":"<p>This plot_energies.{py, ipynb} script visualises the total, kinetic, and potential energies of particles throughout an SPH simulation by plotting them against time. Additionally, it plots the evolution of the adaptive timestep used in the simulation over time. The data is extracted from a CSV file containing energy and timestep values at different simulation moments.</p> <p>The script uses two Python modules; the pandas module to read the energy and timestep data from the generated CSV file and the matplotlib module to create and display the visualisations of all the types of energies measured during the simulation in a single plot.</p> Output of the plot_energies.{py, ipynb} scripts: Plots of the energy and the timstep evolutions."},{"location":"A4.Post_Analysis/#usage_1","title":"Usage:","text":"<ul> <li>Ensure you have the following libraries installed in your Python environment : pandas, matplotlib.</li> <li>Run the script from the command line, using the command <code>python plot_energies.py.</code>, or run it as a Jupyter notebook, by executing the notebook cells of the <code>plot_energies.ipynb</code>.</li> </ul>"},{"location":"A4.Post_Analysis/#inputs_1","title":"Inputs:","text":"<ul> <li>CSV file (energies.csv) containing columns for time (Timestamp), timestep (Timestep), kinetic energy (Ek), potential energy (Ep), and total energy (Etotal).</li> </ul>"},{"location":"A4.Post_Analysis/#outputs_1","title":"Outputs:","text":"<ul> <li>Two line plots side-by-side. The left one displays the total, kinetic, and potential energies of particles as functions of time, while the right one displays the adaptive timestep of the simulation over time.</li> </ul>"},{"location":"A4.Post_Analysis/#assumptions_1","title":"Assumptions:","text":"<ul> <li>The expected CSV file format adheres to the specified column names (Timestamp, Timestep, Ek, Ep, Etotal).</li> </ul>"},{"location":"A4.Post_Analysis/#3-simulation-animation","title":"3. Simulation Animation","text":"<p>This simulation_animation.{py, ipynb} script generates an animation visualising the positions and energy evolution of particles, along with the progression of the size of the adaptive timestep used in an SPH simulation across its duration. It dynamically reads data from CSV files containing particle positions and energy and timestep values at different time points of the simulation. The animation depicts both a scatter plot for particle positions and line plots, one for the total, kinetic, and potential energies over time and one for the adaptive timestep.</p> <p>The script uses two Python modules; the pandas module to read the data from the CSV files they are stored in and the matplotlib module to create and display the dynamic visualisations of the initial and final positions and the energies of the particles.</p> <p>The number of animation frames is automatically calculated based on the <code>desired_animation_duration</code>, which is automatically calculated based on the simulated time, and the set <code>frame_rate</code>, resulting in a smooth and informative representation of the simulation's progress. This dynamic and adaptable approach ensures the animation effectively captures the key aspects of the SPH simulation for analysis and visualisation purposes.</p> <p>The code of this script is structured in different functions to provide a concrete separation of concerns for each part of the code.</p> <ul> <li>get_axes_limits: gets the axes limits for the positions plot from the input domain.txt file</li> <li>calculate_num_particles: dynamically determines the number of particles used in the SPH simulation using the generated simulation-positions.csv file. This is required as the number of particles can be potentially different than the one provided by the application user, when it is decided this is needed to properly perform the simulation, such as when the initial condition is set to droplet.</li> <li>create_figure: builds the final plot figure that shows the animated position and energy and adaptive timestep data</li> <li>update: this function is utilised by the <code>FuncAnimation</code> function of the matplotlib.animation class to update the plot at each frame of the animation</li> <li>create_animation: coordinates the creation of the animation of the particles' positions, energies, and adaptive timesteps and stores the generated plot in an MP4 file</li> </ul> Output of the simulation_animation.{py, ipynb} scripts: Animation of the particles' positions, energies and timstep evolutions."},{"location":"A4.Post_Analysis/#usage_2","title":"Usage:","text":"<ul> <li>Ensure you have the following libraries installed in your Python environment: pandas, matplotlib.</li> <li>Run the script from the command line, using the command <code>python simulation_animation.py.</code>, or run it as a Jupyter notebook, by executing the notebook cells of the <code>simulation_animation.ipynb</code> file.</li> </ul>"},{"location":"A4.Post_Analysis/#output","title":"Output:","text":"<ul> <li>An animated MP4 file named fluid_simulation_\\&lt;timestamp&gt;.mp4 is saved in the script's directory (i.e. /post/), visualising the SPH simulation dynamics.</li> </ul>"},{"location":"A4.Post_Analysis/#details","title":"Details:","text":"<p>The animation depicts particle positions using scatter plots and tracks their motion through time. Three energy lines represent the total, kinetic, and potential energies of the system throughout the simulation. The animation duration is set based on the simulation time and a configurable frame rate. This script leverages dynamic particle count determination and customisable styles for a versatile animation experience.</p>"},{"location":"A4.Post_Analysis/#assumptions_2","title":"Assumptions:","text":"<ul> <li>The expected CSV file formats conform to specified column names (Position_X, Position_Y, Timestamp, Timestep, Ek, Ep, Etotal).</li> <li>The number of timesteps is the same between the two files holding the position and energy data, i.e. simulation-positions.csv and energies.csv</li> </ul>"},{"location":"B1.Clang_Format/","title":"Clang Format","text":"<p><code>clang-format</code> is a set of tools to format your codebase based on given styles (or styles created by the user in a config file). It can be used for the following languages: C/C++/Java/JavaScript/JSON/Objective-C/Protobuf/C#. It is a project of LLVM. More in depth information about the actual documentation can be found here.</p> <p>In this project, we have implemented two ways to format C++ code. One way is a manual implementation with a bash script, the other is automatically on git commits using git hooks.</p>"},{"location":"B1.Clang_Format/#format-using-a-bash-script","title":"Format using a bash script","text":"<p>This approach involves a \"manual\" formatting step. The root directory of this project contains a bash script <code>clang-format.sh</code> which contains commands designed to automatically format each <code>.cpp</code> and <code>.h</code> file located in the root directory of the repository. Since <code>clang-format</code> lacks inherent recursive capabilities, it becomes necessary to identify each file and apply formatting individually.</p>"},{"location":"B1.Clang_Format/#1-finding-the-root-directory","title":"1. Finding the root directory","text":"<p>The first command in <code>clang-format.sh</code> finds the root directory and navigates to it using the following command:</p> <pre><code>cd -- \"$(find ~/ -type d -name ReCoDE-SPH-solver-2D-NS | head -1)\"\n</code></pre> <p>This command looks for a directory (<code>-type d</code>) with a name matching that of the repository (<code>-name ReCoDE-SPH-solver-2D-NS</code>). It is important to note that, should the repository have a different name, the value of this flag should be adjusted accordingly. Subsequently, we capture the output of the <code>find</code> command and pipe(<code>|</code>) it to <code>head</code>, which extracts the first(<code>-1</code>) line (a precaution in case the specified name appears multiple times on the host machine). The outcome of this combined effort is then passed to <code>cd</code> to navigate to the correct location.</p>"},{"location":"B1.Clang_Format/#2-choosing-the-style-guide","title":"2. Choosing the Style Guide","text":"<p>The style guide defines the rules clang-format will use to format your code. The default style guide is llvm, but we can choose any other pre-defined style guide, or we could define our own. Here we choose the pre-defined googlestyle.</p> <pre><code>if ! [ -f \"$config_file\" ]; then\n    clang-format --style=google --dump-config &gt; \"$config_file\"\nfi\n</code></pre> <p>This command searches the current directory for the specified config file and, in the case it's not present, creates it on the spot to be used by <code>clang-format</code>.</p>"},{"location":"B1.Clang_Format/#3-format-cpp-and-header-files","title":"3. Format CPP and header files","text":"<p>The final command performs the code formatting for every CPP and header file.</p> <pre><code>find . \\( -name '*.cpp' -o -name '*.h' \\) -exec clang-format -i {} +\n</code></pre> <p>This command finds every <code>.cpp</code> and <code>.h</code> file inside the current directory and passes them to <code>clang-format</code> to format them. Should the <code>find</code> command locate any CPP or header files, formatting will be applied to these files. In the absence of matching files, the command won't encounter an error, but it's essential to include the + symbol in the <code>find</code> command. This ensures that even if no files are found, an empty string is passed to clang-format as expected.</p>"},{"location":"B1.Clang_Format/#usage","title":"Usage","text":"<p>In order to use the formatter, you need to run the following command in the terminal in the root directory of the project:</p> <pre><code>./clang-format.sh\n</code></pre> <p>This runs the script. The formatter then proceeds to format all the detected files using the style rules provided in the clang configuration file. If the user wants to change the style of the formatting applied, they need to edit <code>clang-format.sh</code> to change the <code>--style</code> flag's value to the desired style guide for clang follow. Some suggestions can be found here.</p>"},{"location":"B1.Clang_Format/#format-on-commit","title":"Format on commit","text":"<p>Another approach we could take is to automate the running of <code>clang</code>. We do this by using the <code>pre-commit</code> Python package to automate the process of formatting our staged files on every <code>git commit</code>. This way of code formatting is independent of the manual way and you don't need to use both to format your code or for them to work properly.</p> <p>There is a configuration file for <code>pre-commit</code> (<code>.pre-commit-config.yaml</code>), in which a pre-commit git hook is specified. To install this hook to a local git repository the following command is required:</p> <pre><code>pre-commit install\n</code></pre> <p>Following this, every time the <code>git commit</code> command is executed, any \"bad formatted\" staged files are detected and formatted by <code>pre-commit</code>, based on the clang-format configuration that has been specified. Moreover, the commit fails with a message that prompts the user to stage the files that were formatted by the package and make a new commit. In the case that all the staged files are formatted according to the specified style rules, the commit will succeed with an appropriate message.</p> <p>More information on the <code>pre-commit package</code> can be found here.</p>"},{"location":"B1.Clang_Format/#format-checking-pipeline","title":"Format Checking Pipeline","text":"<p>Furthermore, we have implemented a final, holistic check of our code's format. Using a Github Actions workflow (defined in <code>format.yml</code>), we have developed a pipeline that is triggered every time a git push happens or a Pull Request (PR) is opened.</p> <p>The pipeline checks all the <code>.cpp</code> and <code>.h</code> files in the repository, using the clang-format Github Action defined here. If all the files are formatted based on the clang-format configuration that has been specified, the pipeline succeeds, else it fails. This pipeline, combined with the appropriate branch rules, guarantees that our Github repository is always well-formatted.</p>"},{"location":"B2.CMake/","title":"Building with CMake","text":"<p>CMake is a tool that facilitates the build of large projects written in C++. It takes care of all the linking and dependency fetching for the user. Moreover, it provides a user-friendly scripting language format, enabling the user to specify the building steps using code. More information about how to use CMake can be found in the official CMake page.</p>"},{"location":"B2.CMake/#cmakelists-file","title":"CMakeLists file","text":"<p>Everything related to CMake should be inside a file called <code>CMakeLists.txt</code>. Without it, <code>cmake</code> cannot start the procedure of building the project. There is a plethora of features in modern CMake and extensive documentation about it. For the purpose of this project, the CMake functionality that is required and used is limited, thus only some of these features are mentioned and described.</p>"},{"location":"B2.CMake/#cmake-flags","title":"CMake Flags","text":"<p>In the beginning of the <code>CMakeLists.txt</code>, it's possible to incorporate various flags. These flags can be related to CMake (e.g <code>cmake_minimum_required(VERSION 3.26)</code>) or to C++ (e.g <code>set(CMAKE_CXX_STANDARD 20)</code>). For example, the latter flag sets the C++ Standard for the CMake build.</p>"},{"location":"B2.CMake/#project","title":"Project","text":"<p>You start the build (or project as called inside CMakeLists.txt by naming the final outcome of the build using project()) <p>When the CMake building process completes, a binary output is produced. It is good practice to specify where this binary will reside when the build is done. This is done with the following lines:</p> <pre><code>set(CMAKE_BINARY_DIR ${CMAKE_SOURCE_DIR}/build)\nset(EXECUTABLE_OUTPUT_PATH ${CMAKE_BINARY_DIR})\n</code></pre> <p>Here, we store the generated binary within a folder of the CMake source directory, called build.</p> <p>CMake has some internal variables that can be accessed using <code>${}</code>, as seen in the code above with <code>${CMAKE_SOURCE_DIR}</code>. More information about these variables can be found here.</p>"},{"location":"B2.CMake/#sources","title":"Sources","text":"<p>The <code>SOURCES</code> attribute specifies all the source files that are used in the build of the project. In the case that the C++ project contains many source and many header files, it is considered a good practice to specify them separately, as follows:</p> <pre><code>set(SOURCES\n    &lt;all_of_sources&gt;)\nset(INCLUDES\n    &lt;all_of_headers&gt;)\n\nadd_executable(&lt;project_name&gt; &lt;main_cpp&gt; ${SOURCES} ${INCLUDES})\n</code></pre> <p>For this project, this is not necessary, as there are only five files.</p>"},{"location":"B2.CMake/#external-dependencies-boost","title":"External Dependencies (Boost)","text":"<p>CMake is great in fetching and linking any external dependency that a C++ project might require. It's especially helpful with Boost, which is utilised by this project, as it can use <code>find_package</code> and fetch the existing installation. When finding packages, it is best practice to include only the headers that the user requires (in our case <code>program_options</code>).</p> <p>In the case the Boost package is found, we can add the output executable (<code>SPH_SOLVER</code>) and link it to the <code>SOURCE</code> files we have declared earlier (CMake will go and fetch them automatically).</p> <p>For Boost to work, one more step is required. We need to link Boost's libraries to the target (<code>SPH_SOLVER</code>). This is done using the <code>target_link_libraries</code> command.</p>"},{"location":"C1.Exercises/","title":"Exercises","text":"<p>A codebase can never be perfect. One can always identify and propose new improvements or modifications which suit their different tastes and programming styles. The present project is no different, and therefore additions to the functionality and improvement of the performance are of course possible. The following set of exercises, proposes possible directions which can be followed in order to further improve the code. You may wish to attempt some of these improvements as exercises to practice and build upon the knowledge you have acquired.</p>"},{"location":"C1.Exercises/#inputs-outputs","title":"Inputs - Outputs","text":"<ul> <li> <p>Although most inputs of the code are being stored in input files and read by the program at runtime, the initial velocity of the particles is always set to 0.0 through a hardcoded value in the <code>ic</code> functions. The purpose of this exercise is for you to attempt to create new input variables which will be read by the program and initialize the velocities of the particles.</p> </li> <li> <p>Most scientific codes which involve time integration processes, have the functionality of restarting the solution from a previously computed state. In that way, the user doesn't always have to start from scratch. To achieve that you have to:</p> <p>1) In the function <code>initOutputFiles()</code> create new output files dedicated to restarting the process. 2) Introduce a new boolean variable to inform the program whether to restart or not. 3) Write a new function which will read the restart files and initialize the particles velocities and positions.</p> </li> </ul> <p>In the case of restart, do you need to invoke the <code>ic</code> functions?</p>"},{"location":"C1.Exercises/#object-oriented-programming","title":"Object Oriented Programming","text":"<ul> <li>The <code>initialise()</code> function of the main program incorporates a lot of different functions with discrete functionalities. Could these functions be considered as member functions encapsulated in a new class which will handle the initialization process?</li> </ul> <p>It is recommended to read what an abstract class is. Would this idea be applicable to the previously described class and the <code>SphSolver</code> class?</p>"},{"location":"C1.Exercises/#stl-and-profiling","title":"STL and Profiling","text":"<ul> <li> <p>The use of <code>std::vectors</code> is associated with an overhead compared to the use of C style arrays due to the former's more complicated structure. There are several vectors in the present code that are only used to store their data and none of their methods is invoked. You may attempt to change them to C style arrays but with the use of <code>std::unique_pointers</code>, to avoid introducing memory leaks. Use the proposed profiling tools and processes to observe any effects on the computational efficiency of the code.</p> </li> <li> <p>In the <code>SphSolver</code> class and the functions <code>SphSolver::neighbourParticlesSearch</code> and <code>SphSolver::placeParticlesInCells</code>, we make use of the variable <code>memoryReservationFactor</code>. Try tweaking this parameter, and by using the timing and profiling tools, observe the impact of that in the performance of the code in big cases.</p> </li> </ul>"},{"location":"C1.Exercises/#post-processing","title":"Post Processing","text":"<ul> <li>In scientific papers one of the most important selling points are your figures and their presentation. You can attempt to modify the generated visualizations and plots, by changing the color and size of the particles, of the lines and of the text on the figures.</li> </ul>"}]}